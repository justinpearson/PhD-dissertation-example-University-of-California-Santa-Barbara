% This file was created with JabRef 2.10.
% Encoding: UTF-8

@Article{PearsonHespanhaLiberzonMay2017,
  author =    {Justin Pearson and Jo{\~a}o Pedro Hespanha and Daniel Liberzon},
  title =    {Control with minimal cost-per-symbol encoding and quasi-optimality of event-based
                  encoders},
  journal =    "IEEE Trans. on Automat. Contr.",
  year =    2017,
  month =    "May",
  number =    5,
  volume =    62,
  pages =    {2286--2301},
  annote =       "Available at \url{http://www.ece.ucsb.edu/~hespanha/published}",
}

@manual{Senn:20092,
  title  = "Using {\LaTeX} for Your Thesis",
  author = "Mark Senn",
  note   = "\url{http://engineering.purdue.edu/~mark/puthesis}",
  year   = "2009 (accessed February 3, 2014)"
}

@manual{pasm1,
  title  = "PRU Assembly Instructions",
  author = "Texas Instruments",
  note   = "\url{http://processors.wiki.ti.com/index.php/PRU_Assembly_Instructions}",
  year   = "2017 (accessed January 23, 2017)"
}

@manual{pasm2,
  title  = "PRU Assembly Reference Guide",
  author = "Texas Instruments",
  note   = "\url{http://processors.wiki.ti.com/index.php/PRU_Assembly_Reference_Guide}",
  year   = "2017 (accessed January 23, 2017)"
}


@manual{github:beaglebone-motor-demo,
  title  = "Beaglebone Motor Demo",
  author = "Justin Pearson",
  note   = "\url{https://github.com/justinpearson/Beaglebone-Motor-Demo}",
  year   = "2017 (accessed Feb 13, 2017)"
}

@manual{github:beaglebone-command-line,
  title  = "Beaglebone drives a motor from the command line",
  author = "Justin Pearson",
  note   = "\url{https://github.com/justinpearson/Beaglebone-motor-from-command-line}",
  year   = "2017 (accessed Jan 27, 2017)"
}






@InBook{flum2010parameterizedBinomialCoefficient,
  Annote                   = {Available at \url{http://www.springerlink.com/content/hkl3hv3755137375/fulltext.pdf}},
  Crossref                 = {flum2010parameterized},
  File                     = {:home/justinpearson/mineng/RelatedWork/fulltext.pdf:PDF},
  Jppkeywords              = {mineng,binomial},
  Page                     = {427},
  Review                   = {From \url{http://en.wikipedia.org/wiki/Binomial_coefficient}:
\begin{quote}
The sum of binomial coefficients can be bounded by a term exponential
in and the binary entropy of the largest $n/k$ that occurs. More
precisely, for $n \ge 1$ and $0<\epsilon<1/2$, it holds
\begin{align}
\sum_{k=0}^\lfloor \epsilon n \rfloor \binom{n}{k} \le 2^{H(\epsilon)n},
\end{align}
where is the binary entropy of $\epsilon$.
See e.g. Flum \& Grohe (2006, p. 427)
Flum, Jörg; Grohe, Martin (2006). Parameterized Complexity Theory. Springer. ISBN 978-3-540-29952-3.
Here is that chapter (found through the UCSB library, which has the e-book):
\end{quote}
}
}

@Misc{GuptaSpanosHassibiMurray2005_2,
  Note                     = {Submitted},

  Crossref                 = {1469960},
  File                     = {:home/justinpearson/mineng/RelatedWork/gshm05-acc.pdf:PDF},
  Journal                  = {2005 American Control Conference}
}

@InCollection{Astrom2007,
  Title                    = {Event Based Control},
  Author                   = {Astr{\"o}m, K.J.},
  Booktitle                = {Analysis and Design of Nonlinear Control Systems: In Honor of Alberto Isidori},
  Publisher                = {Springer Verlag},
  Year                     = {2007},
  Pages                    = {127},
  Annote                   = {Available at \url{http://www.springerlink.com/content/q12685l04rk96043/fulltext.pdf}},
  File                     = {:home/justinpearson/mineng/RelatedWork/astrom_event_based_control.pdf:PDF},
  Jppkeywords              = {mineng, event-based}
}

@Article{andrievsky2010control,
  Title                    = {Control and estimation under information constraints: Toward a unified theory of control, computation and communications},
  Author                   = {Andrievsky, Boris Rostislavovich and Matveev, Aleksei Serafimovich and Fradkov, Aleksandr L'vovich},
  Journal                  = {Automation and Remote Control},
  Year                     = {2010},
  Number                   = {4},
  Pages                    = {572--633},
  Volume                   = {71},

  Abstract                 = {An attempt is made to overview an emerging area of research devoted to analysis and design of control systems under constraints caused by limited information capacity of communication channels. The problem’s prehistory dating back to the 1960s–1970s, as well as the new approaches that appeared during the last decade were analyzed. Much attention was paid to various versions of the celebrated data rate theorem. Consideration was given to the problems of control through the communication networks and some results obtained for the nonlinear systems. The basic application areas were listed in brief.},
  File                     = {:home/justinpearson/mineng/RelatedWork/art%3A10.1134%2FS000511791004003X.pdf:PDF},
  Publisher                = {Springer}
}

@InProceedings{AstromBernhardsson2002,
  Title                    = {Comparison of {R}iemann and {L}ebesgue sampling for first order stochastic systems},
  Author                   = {Astr{\"o}m, K.J. and Bernhardsson, B.M.},
  Booktitle                = {Decision and Control, 2002, Proceedings of the 41st IEEE Conference on},
  Year                     = {2002},
  Month                    = {dec.},
  Pages                    = {2011 - 2016},
  Volume                   = {2},

  Abstract                 = { The normal approach to digital control is to sample
periodically in time. Using an analog of integration theory we can
call this Riemann sampling. Lebesgue sampling or event based sampling
is an alternative to Riemann sampling. It means that signals are
sampled only when measurements pass certain limits. In this paper it
is shown that Lebesgue sampling gives better performance for some
simple systems.},
  Doi                      = {10.1109/CDC.2002.1184824},
  File                     = {:home/justinpearson/mineng/RelatedWork/01184824.pdf:PDF},
  ISSN                     = {0191-2216 },
  Keywords                 = { Lebesgue sampling; Riemann sampling; digital control; first
order stochastic systems; feedback; signal sampling; stochastic
systems;}
}

@Misc{Baillieul2007,
  Title                    = {"Robust and efficient quantization and coding for control of multidimensional linear systems under data rate constraints"},

  Author                   = {John Baillieul},

  Annote                   = {"Available at \url{http://people.bu.edu/johnb/IJRNC07.pdf}"},
  Department               = {Systems Engineering},
  File                     = {:home/justinpearson/mineng/RelatedWork/IJRNC07.pdf:PDF},
  Institution              = {Boston University},
  Website                  = {\url{http://people.bu.edu/johnb/}}
}

@article{li2007robust,
  title={Robust and efficient quantization and coding for control of multidimensional linear systems under data rate constraints},
  author={Li, K and Baillieul, J},
  journal={International Journal of Robust and Nonlinear Control},
  volume={17},
  number={10-11},
  pages={898--920},
  year={2007},
  publisher={Wiley Online Library},
   File                     = {:home/justinpearson/mineng/RelatedWork/IJRNC07.pdf:PDF},
}

@inproceedings{li2004robust,
  title={Robust quantization and coding for multidimensional linear systems under data rate constraints},
  author={Li, K and Baillieul, J},
  booktitle={Decision and Control, 2004. CDC. 43rd IEEE Conference on},
  volume={2},
  pages={1920--1925},
  year={2004},
  organization={IEEE},
  File = {:home/justinpearson/mineng/RelatedWork/0327_WeB03.2.pdf:PDF}
}

@Misc{web:nnsquad,
  Title                    = {NNSquad Network Measurement Agent (NNMA) -- Spoofed Reset Detection Methodology},

  Author                   = {John Bartas and Lauren Weinstein},
  Year                     = {2008},

  Review                   = {[Online; accessed 19-March-2014]},
  Url                      = {http://www.nnsquad.org/nnma-methodology.html}
}

@InBook{berger2003,
  Title                    = {Rate-Distortion Theory},
  Author                   = {Berger, Toby},
  Publisher                = {John Wiley and Sons, Inc.},
  Year                     = {2003},

  Abstract                 = {Rate-distortion theory is the branch of information theory that treats compressing the data produced by an information source down to a specified encoding rate that is strictly less than the source's entropy. This necessarily entails some lossiness, or distortion, between the original source data and the best approximation thereto that can be produced on the basis of the encoder's output bits. Rate-distortion theory was introduced in the seminal works written in 1948 and 1959 by C. E. Shannon, the founder of information theory. We describe Shannon's contribution and then trace its subsequent development worldwide. Heavier than usual emphasis is placed on the concept of “matching” a channel to a source in the rate-distortion sense, and also on the analogous matching of a source to a channel. Experimental evidence has been mounting in support of the hypothesis that living organisms often simultaneously achieve both of these matchings when processing their sensory inputs, thereby eliminating the need for the complex encoding and decoding operations that are needed in order to produce an information-theoretically optimum system in the absence of such double matching.},
  Booktitle                = {Wiley Encyclopedia of Telecommunications},
  Doi                      = {10.1002/0471219282.eot142},
  ISBN                     = {9780471219286},
  Keywords                 = {rate-distortion, lossy source coding, distortion measure, Shannon, joint source-channel coding, bioinformation theory},
  Url                      = {http://dx.doi.org/10.1002/0471219282.eot142}
}

@Book{berger1971rate,
  Title                    = {Rate Distortion Theory: A Mathematical Basis for Data Compression},
  Author                   = {Berger, T.},
  Publisher                = {Prentice-Hall},
  Year                     = {1971},
  Series                   = {Prentice-Hall electrical engineering series},

  ISBN                     = {9780137531035},
  Lccn                     = {75148254},
  Review                   = {src -> src enc -> ch enc -> channel -> ch dec -> src dec -> user.

The src enc has a hard job bc it is a many-to-one mapping from all src outputs to the index of some equivalence class of representative ouptuts. Similarly, a ch dec has a tough job bc it must maps the many noisy outputs of the channel into a representative few that the src dec can one-to-one map to something the user can obsrve. 

A (src/user) pair is: 1. statistical descriptino of the src 2. distortion metric describing the user's ability to discern the difference between it and the src output.

Given src p(x) and user metric d, a src produces R(D) bits/symbol ``of fidelity D'' (the 'of fidelity D' req's d() in order to have meaning). R(D) is a property of the (src,user) pair (the (p(x),d()) pair). R(D) is a genarlizaaation of entorpy bc when d is such that perfect reproduction has 0 distortion, then R(0) = H(X).

},
  Url                      = {http://books.google.com/books?id=-HV1QgAACAAJ}
}

@Article{BrockettLiberzon2000,
  Title                    = {Quantized feedback stabilization of linear systems},
  Author                   = {Brockett, R.W. and Liberzon, D.},
  Journal                  = {Automatic Control, IEEE Transactions on},
  Year                     = {2000},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {1279-1289},
  Volume                   = {45},

  Abstract                 = {This paper addresses feedback stabilization problems for linear time-invariant control systems with saturating quantized measurements. We propose a new control design methodology, which relies on the possibility of changing the sensitivity of the quantizer while the system evolves. The equation that describes the evolution of the sensitivity with time (discrete rather than continuous in most cases) is interconnected with the given system (either continuous or discrete), resulting in a hybrid system. When applied to systems that are stabilizable by linear time-invariant feedback, this approach yields global asymptotic stability},
  Doi                      = {10.1109/9.867021},
  File                     = {:home/justinpearson/mineng/RelatedWork/brockett00quantized.pdf:PDF},
  ISSN                     = {0018-9286},
  Keywords                 = {asymptotic stability;continuous time systems;control system synthesis;discrete time systems;linear systems;sensitivity analysis;state feedback;asymptotic stability;continuous time systems;discrete time systems;hybrid systems;linear time-invariant systems;sensitivity analysis;stabilization;state feedback;Asymptotic stability;Communication system control;Control design;Control systems;Equations;Feedback control;Linear feedback control systems;Linear systems;Output feedback;Quantization}
}

@InProceedings{CervinAstromDec2007,
  Title                    = {On Limit Cycles in Event-Based Control Systems},
  Author                   = {Cervin, Anton and Astr{\"o}m, K.J.},
  Booktitle                = {Proc. 46th IEEE Conference on Decision and Control},
  Year                     = {2007},

  Address                  = {New Orleans, LA},
  Month                    = dec,

  Abstract                 = {Abstract— Event-based control is a promising alternative
to time-triggered control, especially for systems with limited
computation and communication capacities. In the paper, the
architecture of a general structure for event-based control is
presented. The resulting system has many interesting proper-
ties. For instance, a constant load disturbance will typically
make the process output oscillate according to a stable limit
cycle. Necessary conditions for the limit cycle are given and
its local stability is analyzed. Finally, a simple way to achieve
integral action based on times between events is proposed.
},
  Annote                   = {Available at \url{http://www.control.lth.se/documents/2007/cer+ast07.pdf}},
File = {:home/justinpearson/mineng/RelatedWork/cer+ast07.pdf:PDF}
}

@Book{como2013information,
  Title                    = {Elements of information theory for networked control systems},
  Author                   = {Como, G. and Bernhardsson, B. and Rantzer, A. and M.Franceschetti and P. Minero},
  Publisher                = {Springer International Publishing},
  Year                     = {2013},
  Series                   = {Lecture Notes in Control and Information Sciences},

  Booktitle                = {Information and Control in Networks},
  Chapter                  = {1},
  File                     = {:home/justinpearson/mineng/RelatedWork/Elements.pdf:PDF},
  ISBN                     = {9783319021492},
  Url                      = {http://books.google.com/books?id=HiQYngEACAAJ}
}

@Book{cover2012elements,
  Title                    = {Elements of Information Theory},
  Author                   = {Cover, T.M. and Thomas, J.A.},
  Publisher                = {Wiley},
  Year                     = {2012},

  Annote                   = {"Available at \url{http://books.google.com/books?id=VWq5GG6ycxMC}"},
  ISBN                     = {9781118585771},
  Review                   = {

 Rate distortion.



 Given:
 \begin{itemize}
 \item Information source: rv $X \sim p(x)$ taking values in $\scr{X}$
 \item User: Reconstruction set $\scr{X}'$ and distortion metric: $d : \scr{X} \times \scr{X}' \to \NNReal$,
 \end{itemize}

 Consider some $(2^{nR},n)$ code, that is, encoder $f : \scr{X}^n \to
 \{1,\ldots,2^{nR} \}$ and decoder $g : \{1,\ldots,2^{nR}\} \to
 \hat{\scr{X}}^n$. Then $g(f(X))$, a rv, is the reconstructed symbol, and $d(X,gfX)$, a rv, is the distortion suffered.

 Want:
 \begin{itemize}
 \item Bits per symbol $R$ small
 \item Expected distortion $\mathbb{E} d(X,gfX)$ small
 \end{itemize}

 Compute: The rate distortion function
 \begin{align*}
 R(D) \eqdef \sup_{p(\hat{x}|x) \ | \ \mathbb{E} d(X,gfX)} I(X;\hat{X})
 \end{align*}

 Theorem: $\forall D$ satisfying $R(D)>H(X)$, $\exists$
 $(2^{nR},n)$ code for some $n$ and $R$ satisfying $R=R(D)$ that
 achieves less distortion than $D$.


 Data Compression:

 Info src $X \sim p(x)$ takes values in $\scr{X}$. Code $C : \scr{X} \to \{0,1\}^*$. 

 Prefix-free = instantaneous code. Now you can extend the code to accept $x^n \in \scr{X}^n$ and concatenate the $C(x_i)$. 

 Length of an emitted codeword is a rv $|C(X)|$. Length of $n$
 inputs is $|C(X^n)|$. Length per input symbol is also a rv,
 $|C(X^n)|/n$. Its expected value (over the info src) depends on
 the info src $X$ and the code $C$, and is the avg number of bits
 per input symbol that the code employs.

 Thm: For any info src $X$, for any $n$, there exists a prefix-free code $C$ with
 \begin{align*}
 H(X) \le \mathbb{E} |C(X^n)|/n \le H(X) + 1/n
 \end{align*}



 
 Questions:
 \begin{itemize}
 \item Difference between rate distortion and channel coding? pg 325
 \item $C$ is the log of num of distinguishable inputs? What?
 \item Sometimes we have $1,\ldots,M$ messages in the input. sometimes we have an info src. What governs which problem setup we have?
 \item Is source channel coding a special case of rate-distortion where d equals the discrete metric?
 \end{itemize}

 
 Keywords to learn:
 \begin{itemize}
 \item Data compression
 \item rate distortion
 \item source-channel coding
 \item shannon's noisy channel coding thm
 \item Gaussian channels
 \item differential entropy and cts rv's
 \item Band-limited gaussian channel
 \item power-limited coding of a gaussian channel
 \item data-processing inequality
 \item rate distortion version of source-channel coding thm.
 \end{itemize}




 }
}

@Article{tabuadaDonkers2014,
  Title                    = {Minimum attention control for linear systems},
  Author                   = {Donkers, M.C.F. and Tabuada, P. and Heemels, W.P.M.H.},
  Journal                  = {Discrete Event Dynamic Systems},
  Year                     = {2014},
  Number                   = {2},
  Pages                    = {199-218},
  Volume                   = {24},

  Abstract                 = {In this paper, we present a novel solution to the minimum attention control problem for linear systems. In minimum attention control, the objective is to minimise the ‘attention’ that a control task requires, given certain performance requirements. Here, we interpret ‘attention’ as the inverse of the interexecution time, i.e., the inverse of the time between two consecutive executions. Instrumental for our approach is a particular extension of the notion of a control Lyapunov function and the fact that we allow for only a finite number of possible interexecution times. By choosing this extended control Lyapunov function to be an ∞-norm-based function, the minimum attention control problem can be formulated as a linear program, which can be solved efficiently online. Furthermore, we provide a technique to construct a suitable ∞-norm-based (extended) control Lyapunov function. Finally, we illustrate the theory using a numerical example, which shows that minimum attention control outperforms an alternative ‘attention-aware’ control law available in the literature.},
  Doi                      = {10.1007/s10626-012-0155-x},
  File                     = {:home/justinpearson/mineng/RelatedWork/DonTab_DEDS_12.pdf:PDF},
  ISSN                     = {0924-6703},
  Keywords                 = {Self-triggered control; Attention-aware control; Infinity-norm based Lyapunov functions; Linear programmingx},
  Language                 = {English},
  Publisher                = {Springer US},
  Url                      = {http://dx.doi.org/10.1007/s10626-012-0155-x}
}

@Article{948466,
  Title                    = {Stabilization of linear systems with limited information},
  Author                   = {Elia, N. and Mitter, S.K.},
  Journal                  = {Automatic Control, IEEE Transactions on},
  Year                     = {2001},

  Month                    = {Sep},
  Number                   = {9},
  Pages                    = {1384-1400},
  Volume                   = {46},

  Abstract                 = {We show that the coarsest, or least dense, quantizer that quadratically stabilizes a single input linear discrete time invariant system is logarithmic, and can be computed by solving a special linear quadratic regulator problem. We provide a closed form for the optimal logarithmic base exclusively in terms of the unstable eigenvalues of the system. We show how to design quantized state-feedback controllers, and quantized state estimators. This leads to the design of hybrid output feedback controllers. The theory is then extended to sampling and quantization of continuous time linear systems sampled at constant time intervals. We generalize the definition of density of quantization to the density of sampling and quantization in a natural way, and search for the coarsest sampling and quantization scheme that ensures stability. Finally, by relaxing the definition of quadratic stability, we show how to construct logarithmic quantizers with only finite number of quantization levels and still achieve practical stability of the closed-loop system},
  Doi                      = {10.1109/9.948466},
  File                     = {:home/justinpearson/mineng/RelatedWork/elia_mitter_2001_10.1.1.80.2964.pdf:PDF},
  ISSN                     = {0018-9286},
  Keywords                 = {Lyapunov methods;closed loop systems;continuous time systems;discrete time systems;linear quadratic control;linear systems;stability;state estimation;state feedback;closed-loop system;continuous time systems;discrete time systems;eigenvalues;linear quadratic control;linear systems;optimal control;quantization;sampling;stability;state estimation;state-feedback;Communication system control;Control systems;Eigenvalues and eigenfunctions;Linear systems;Quantization;Regulators;Sampling methods;Stability;State estimation;Time invariant systems}
}

@Misc{web:tcpslowstart,
  Title                    = {Transmission Control Protocol (TCP Connection Setup and Release)},

  Author                   = {EventStudio},
  Year                     = {2014},

  Review                   = {[Online; accessed 20-March-2014]},
  Url                      = {http://www.eventhelix.com/realtimemantra/networking/tcp.pdf}
}

@Book{flum2010parameterized,
  Title                    = {Parameterized Complexity Theory},
  Author                   = {Flum, J.},
  Publisher                = {Springer},
  Year                     = {2010},
  Series                   = {Texts in Theoretical Computer Science. an Eatcs Series},

  ISBN                     = {9783642067570},
  Publisherurl             = {\url{ttp://www.springer.com/computer/theoretical+computer+science/book/978-3-540-29952-3}},
  Url                      = {http://books.google.com/books?id=fZCqcQAACAAJ}
}

@Article{1146101,
  Title                    = {Efficient Modulation for Band-Limited Channels},
  Author                   = {Forney, G.D. and Gallager, R.G. and Lang, G. and Longstaff, F.M. and Qureshi, S.U.},
  Journal                  = {Selected Areas in Communications, IEEE Journal on},
  Year                     = {1984},

  Month                    = {Sep},
  Number                   = {5},
  Pages                    = {632-647},
  Volume                   = {2},

  Abstract                 = {This paper attempts to present a comprehensive tutorial survey of the development of efficient modulation techniques for bandlimited channels, such as telephone channels. After a history of advances in commercial high-speed modems and a discussion of theoretical limits, it reviews efforts to optimize two-dimensional signal constellations and presents further elaborations of uncoded modulation. Its principal emphasis, however, is on coded modulation techniques, in which there is an explosion of current interest, both for research and for practical application. Both block-coded and trellis-coded modulation are covered, in a common framework. A few new techniques are presented.},
  Doi                      = {10.1109/JSAC.1984.1146101},
  File                     = {:home/justinpearson/mineng/RelatedWork/01146101.pdf:PDF},
  ISSN                     = {0733-8716},
  Keywords                 = {Block coding;Pulse-amplitude modulation;Quadrature amplitude modulation;Trellis coding;Bandwidth;Constellation diagram;Explosions;History;Layout;Modems;Modulation coding;Quadrature amplitude modulation;Signal to noise ratio;Telephony}
}

@Misc{FranceschettiNecsys2012,
  Title                    = {A journey through data rate theorems for communication and control},

  Author                   = {Franceschetti, M.},

  Abstract                 = {Massimo reviews the state-of-the-art in communication-constrained control, emphasizing his work.},
  File                     = {:home/justinpearson/mineng/RelatedWork/Franceschetti-NecSys2012.pdf:PDF}
}

@Misc{Gallager1987,
  Title                    = {Energy Limited Channels: Coding, Multiaccess, and Spread Spectrum},

  Author                   = {Robert G. Gallager},
  Month                    = {nov},
  Year                     = {1987},

  File                     = {:home/justinpearson/mineng/RelatedWork/10.1.1.88.6861.pdf},
  Review                   = {I'm not sure where I got this. The closest thing I can find is this guy.}
}

@Book{teel2012hybrid,
  Title                    = {Hybrid Dynamical Systems: Modeling, Stability, and Robustness},
  Author                   = {Goebel, R. and Sanfelice, R.G. and Teel, A.},
  Publisher                = {Princeton University Press},
  Year                     = {2012},

  ISBN                     = {9780691153896},
  Lccn                     = {2011941674},
  UrlBooger                      = {http://books.google.com/books?id=L8qqFWBt3L8C},
  Review = {Available at http://books.google.com/books?id=L8qqFWBt3L8C}
}

@InProceedings{gupta2008rate,
  Title                    = {Rate-distortion in near-linear time},
  Author                   = {Gupta, Ankit and Verdu, Sergio and Weissman, Tsachy},
  Booktitle                = {Information Theory, 2008. ISIT 2008. IEEE International Symposium on},
  Year                     = {2008},
  Organization             = {IEEE},
  Pages                    = {847--851},

  Abstract                 = {Abstract—We present two results related to the computational
complexity of lossy compression. The ﬁrst result shows that for
a memoryless source PS with rate-distortion function R(D), the
rate-distortion pair (R(D) + γ,D + ) can be achieved with
constant decoding time per symbol and encoding time per symbol
proportional to C1(γ)
−C2(γ)
. The second results establishes that
for any given R, there exists a universal lossy compression
scheme with O(ng(n)) encoding complexity and O(n) decoding
complexity, that achieves the point (R, D(R)) asymptotically for
any ergodic source with distortion-rate function D(·), where
g(n) is an arbitrary non-decreasing unbounded function. A
computationally feasible implementation of the ﬁrst scheme
outperforms many of the best previously proposed schemes for
binary sources with blocklengths of the order of 1000.},
  File                     = {:home/justinpearson/mineng/RelatedWork/GupVerWei.ISIT2008.pdf:PDF}
}

@InProceedings{1469960,
  Title                    = {On LQG control across a stochastic packet-dropping link},
  Author                   = {Vijay Gupta and Demetri Spanos and Babak Hassibi and Richard M. Murray},
  Booktitle                = {American Control Conference, 2005. Proceedings of the 2005},
  Year                     = {2005},
  Month                    = {8-10,},
  Pages                    = { 360 - 365},

  Abstract                 = {Not available},
  Doi                      = {10.1109/ACC.2005.1469960},
  File                     = {:home/justinpearson/mineng/RelatedWork/01469960.pdf:PDF},
  ISSN                     = {0743-1619},
  Keywords                 = { Kalman filter; LQG control design; LQR state-feedback; optimal algorithm; optimal linear quadratic Gaussian control; packet drop events; packet drop pattern; sensor-controller communication; separation principle; stochastic packet-dropping link; switched linear filter; unreliable link; Kalman filters; control system synthesis; linear quadratic Gaussian control; optimal control; sensors; stability; state estimation; state feedback; stochastic systems; switched filters;}
}

@InProceedings{heemels2012introduction,
  Title                    = {An introduction to event-triggered and self-triggered control.},
  Author                   = {Heemels, WPMH and Johansson, Karl Henrik and Tabuada, Paulo},
  Booktitle                = {CDC},
  Year                     = {2012},
  Pages                    = {3270--3285},

  Abstract                 = {Abstract— Recent developments in computer and commu-
nication technologies have led to a new type of large-scale
resource-constrained wireless embedded control systems. It is
desirable in these systems to limit the sensor and control
computation and/or communication to instances when the sys-
tem needs attention. However, classical sampled-data control is
based on performing sensing and actuation periodically rather
than when the system needs attention. This paper provides
an introduction to event- and self-triggered control systems
where sensing and actuation is performed when needed. Event-
triggered control is reactive and generates sensor sampling and
control actuation when, for instance, the plant state deviates
more than a certain threshold from a desired value. Self-
triggered control, on the other hand, is proactive and computes
the next sampling or actuation instance ahead of time. The
basics of these control strategies are introduced together with
a discussion on the differences between state feedback and
output feedback for event-triggered control. It is also shown
how event- and self-triggered control can be implemented using
existing wireless communication technology. Some applications
to wireless control in process industry are discussed as well.
},
  File                     = {:home/justinpearson/mineng/RelatedWork/HeeJoh_CDC_12.pdf:PDF}
}

@InCollection{Hespanha2004,
  Title                    = {Stochastic Hybrid Systems: Application to Communication Networks},
  Author                   = {Hespanha, JoãoP.},
  Booktitle                = {Hybrid Systems: Computation and Control},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2004},
  Editor                   = {Alur, Rajeev and Pappas, GeorgeJ.},
  Pages                    = {387-401},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {2993},

  Doi                      = {10.1007/978-3-540-24743-2_26},
  ISBN                     = {978-3-540-21259-1},
  Url                      = {http://dx.doi.org/10.1007/978-3-540-24743-2_26}
}

@InCollection{hespanhaMorse1999,
  Title                    = {Scale-Independent Hysteresis Switching},
  Author                   = {Hespanha, JoãoP. and Morse, A.Stephen},
  Booktitle                = {Hybrid Systems: Computation and Control},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {1999},
  Editor                   = {Vaandrager, FritsW. and van Schuppen, JanH.},
  Pages                    = {117-122},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {1569},

  Abstract                 = {This paper introduces a new switching logic inspired by the hysteresis switching logic considered in [7,11]. The new logic also uses hysteresis to prevent chatter, but unlike its predecessor in [7,11], it is “scale-independent” as well. The logic is shown to have the requisite properties for adaptive control applications.},
  Doi                      = {10.1007/3-540-48983-5_13},
  File                     = {:home/justinpearson/mineng/RelatedWork/si-hyst.ps:PDF},
  ISBN                     = {978-3-540-65734-7},
  Language                 = {English},
  Url                      = {http://dx.doi.org/10.1007/3-540-48983-5_13}
}

@InCollection{HespanhaNov06,
  Title                    = {Stochastic Hybrid Modeling of on-off {TCP} flows},
  Author                   = {Jo{\~a}o Pedro Hespanha},
  Booktitle                = {Stochastic Hybrid Systems: Recent Developments and
 Research Trends},
  Publisher                = {CRC Press},
  Year                     = {2006},

  Address                  = {Boca Raton},
  Editor                   = {Christos G. Cassandras and John Lygeros},
  Month                    = {Nov.},
  Number                   = {24},
  Pages                    = {191--219},
  Series                   = {Control Engineering Series},

  Annote                   = {Available at \url{http://www.ece.ucsb.edu/~hespanha/published}}
}

@Misc{hespanhaWritingPapers,
  Title                    = {Writing a Control Paper},

  Author                   = {Jo{\~a}o Pedro Hespanha},

  Annote                   = {Available at \url{http://www.ece.ucsb.edu/~hespanha/published/writingpapers.pdf}},
  File                     = {:home/justinpearson/mineng/RelatedWork/writingpapers.pdf:PDF},
  Review                   = {Joao's essay detailing how to write a controls paper.}
}

@InProceedings{HespanhaLiberzonMorseDec00,
  Title                    = {Bounds on the Number of Switchings with
 Scale-Independent Hysteresis: Applications to
 Supervisory Control},
  Author                   = {Jo{\~a}o Pedro Hespanha and Daniel Liberzon and
 A.~Stephen Morse},
  Booktitle                = {Proc. of the 39th Conf. on Decision and Contr.},
  Year                     = {2000},
  Month                    = {Dec.},
  Pages                    = {3622-3627},
  Volume                   = {4},

  Annote                   = {Available at \url{http://www.ece.ucsb.edu/~hespanha/published}}
}

@InProceedings{HespanhaOrtegaVasudevanAug02,
  Title                    = {Towards the Control of Linear Systems with Minimum
 Bit-Rate},
  Author                   = {Jo{\~a}o Pedro Hespanha and Antonio Ortega and Lavanya
 Vasudevan},
  Booktitle                = {Proc. of the Int. Symp. on the Mathematical Theory of Networks and Syst.},
  Year                     = {2002},
  Month                    = {Aug.},

  Annote                   = {Available at \url{http://www.ece.ucsb.edu/~hespanha/published}},
  File                     = {:home/justinpearson/mineng/RelatedWork/10.1.1.110.573.pdf:PDF}, 

  Abstract                 = { We address the problem of determining the minimum bit-rate needed to stabilize a linear time-invariant process. For the noise free case, we determine a bit-rate below which stabilization is not possible and above which asymptotic stabilization can be achieved. Inspired by differential pulse code modulation (DPCM) techniques, we propose practical encoding/decoding schemes that guarantee boundedness of the state for the case of a noisy linear time-invariant process. With fixed-step quantization, we are only able to approach the minimum bit-rate for the noiseless case. However, with variable-step quantization we are able to approach it even in the presence of noise and disturbances.}


}

@Book{michael,
  Title                    = {My Kingdom For A Lollypop},
  Author                   = {Michael Jackson},
  Publisher                = {Neverland \& Everland Publishing},
  Year                     = {2004},

  Jppkeywords              = {test}
}

@Article{6142075,
  Title                    = {Energy-Distortion Tradeoffs in Gaussian Joint Source-Channel Coding Problems},
  Author                   = {A. Jain and D. Gunduz and S. Kulkarni and H. V. Poor and S. Verdú},
  Journal                  = {IEEE Trans. on Information Theory},
  Year                     = {2012},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {3153-3168},
  Volume                   = {58},

  File                     = {:home/justinpearson/mineng/RelatedWork/JaiIT2012.pdf:PDF},
  Jppkeywords              = {mineng,infotheory},
  Publisher                = {IEEE},
  Url                      = {"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6142075&queryText%3DEnergy-Distortion+Tradeoffs+in+Gaussian+Joint+Source-Channel++Coding+Problems"}
}

@InProceedings{kostina2013channels,
  Title                    = {Channels with cost constraints: strong converse and dispersion},
  Author                   = {Kostina, Victoria and Verd{\'u}, Sergio},
  Booktitle                = {Information Theory Proceedings (ISIT), 2013 IEEE International Symposium on},
  Year                     = {2013},
  Organization             = {IEEE},
  Pages                    = {1734--1738},

  Abstract                 = {This paper shows the strong converse and the dispersion of memoryless channels with cost con-
straints and performs refined analysis of the third order term in the asymptotic expansion of the maximum
achievable channel coding rate, showing that it is equal to
1 log n
2 n
in most cases of interest. The analysis
is based on a non-asymptotic converse bound expressed in terms of the distribution of a random variable
termed the b-tilted information density, which plays a role similar to that of the d-tilted information in
lossy source coding. We also analyze the fundamental limits of lossy joint-source-channel coding over
channels with cost constraints.
},
  File                     = {:home/justinpearson/mineng/RelatedWork/1401.5124.pdf:PDF}
}

@Article{LiberzonHespanhaJun05,
  Title                    = {Stabilization of nonlinear systems with limited
 information feedback},
  Author                   = {Daniel Liberzon and Jo{\~a}o Pedro Hespanha},
  Journal                  = {IEEE Trans. on Automat. Contr.},
  Year                     = {2005},

  Month                    = {June},
  Number                   = {6},
  Pages                    = {910--915},
  Volume                   = {50},

  Annote                   = {Available at \url{http://www.ece.ucsb.edu/~hespanha/published}},
  File                     = {:home/justinpearson/mineng/RelatedWork/nonlinear-coding-TACversion.pdf:PDF}
}

@Book{marilyn,
  Title                    = {I Love My Little Pony},
  Author                   = {Marilyn Manson},
  Publisher                = {Pinc \& Cuddley Press},
  Year                     = {2005},

  Jppkeywords              = {test}
}

@Article{doi:10.1137/040621697,
  Title                    = {An analogue of {S}hannon information theory for detection and stabilization via noisy discrete communication channels},
  Author                   = {Matveev, A. and Savkin, A.},
  Journal                  = {SIAM Journal on Control and Optimization},
  Year                     = {2007},
  Number                   = {4},
  Pages                    = {1323-1367},
  Volume                   = {46},
File = {:home/justinpearson/mineng/RelatedWork/01429457.pdf:PDF},

  Abstract                 = {The paper addresses a state estimation problem involving bit-rate communication capacity constraints. A discrete-time partially observed linear system is studied. Unlike the classic theory, the sensor signals are transmitted to the estimator over a noisy digital communication channel. A recursive coder-decoder state estimation scheme is proposed and investigated. It is shown that the classic Shannon's noisy channel capacity constitutes the border separating the cases where the reliable state estimation is and, respectively, is not possible with arbitrarily high probability.},
  Doi                      = {10.1137/040621697},
  Eprint                   = { 
 http://dx.doi.org/10.1137/040621697
 
},
  File                     = {:home/justinpearson/mineng/RelatedWork/040621697.pdf:PDF},
  UrlBooger                      = {  http://dx.doi.org/10.1137/040621697},
Notes = {Available at http://dx.doi.org/10.1137/040621697. Um, my pdf of this says ... um...}
}

@Article{MatveevSavkin2005,
  Title                    = {Multirate Stabilization of Linear Multiple Sensor Systems via Limited Capacity Communication Channels},
  Author                   = {Matveev, A. and Savkin, A.},
  Journal                  = {SIAM Journal on Control and Optimization},
  Year                     = {2005},
  Number                   = {2},
  Pages                    = {584-617},
  Volume                   = {44},

  Abstract                 = {The paper addresses a feedback stabilization problem involving bit-rate communication capacity constraints. A discrete-time partially observed linear system is studied. Unlike classic theory, the signals from multiple sensors are transmitted to the controller over separate finite capacity communication channels. The sensors do not have constant access to the channels, and the channels are not perfect: the messages incur time-varying transmission delays and may be corrupted or lost. However, we suppose that the time-average number of bits per sample period that can be successfully transmitted over the channel during a time interval converges to a certain limit as the length of the interval becomes large. Necessary and sufficient conditions for stabilizability are established. They give the tightest lower bounds on the channel capacities for which stabilization is possible. An algorithm for stabilization is also presented.},
  Annote                   = {"Available at \url{http://epubs.siam.org/doi/abs/10.1137/S0363012902419965}"},
  Doi                      = {10.1137/S0363012902419965},
  Eprint                   = {http://epubs.siam.org/doi/pdf/10.1137/S0363012902419965}
}

@InProceedings{1429457,
  Title                    = {An analogue of Shannon information theory for networked control systems: State estimation via a noisy discrete channel},
  Author                   = {Matveev, A.S. and Savkin, A.V.},
  Booktitle                = {Decision and Control, 2004. CDC. 43rd IEEE Conference on},
  Year                     = {2004},
  Month                    = {Dec},
  Pages                    = {4485-4490 Vol.4},
  Volume                   = {4},

  Abstract                 = {The paper addresses a state estimation problem involving bit-rate communication capacity constraints. A discrete-time partially observed linear system is studied. Unlike the classic theory, the sensor signals are transmitted to the estimator over a noisy digital communication channel. A recursive coder-decoder state estimation scheme is proposed and investigated. It is shown that the classic Shannon's noisy channel capacity constitutes the border separating the cases where the reliable state estimation is and, respectively, is not possible with arbitrarily high probability.},
  Doi                      = {10.1109/CDC.2004.1429457},
  ISSN                     = {0191-2216},
  Keywords                 = {channel capacity;discrete time systems;linear systems;recursive estimation;state estimation;Shannon information theory;bit-rate communication capacity constraints;discrete-time partially observed linear system;networked control systems;noisy channel capacity;noisy digital communication channel;noisy discrete channel;recursive coder-decoder state estimation scheme;sensor signals;Channel capacity;Communication system control;Constraint theory;Control systems;Digital communication;Information theory;Mobile communication;Networked control systems;Quantization;State estimation}
}

@Article{doi:10.1080/002071706000981775,
  Title                    = {Shannon zero error capacity in the problems of state estimation and stabilization via noisy communication channels},
  Author                   = {Matveev, A. S. and Savkin, A. V.},
  Journal                  = {International Journal of Control},
  Year                     = {2007},
  Number                   = {2},
  Pages                    = {241-255},
  Volume                   = {80},

  Abstract                 = { The paper addresses state estimation and stabilization problems involving communication errors and capacity constraints. Discrete-time partially observed unstable linear systems perturbed by stochastic exogenous disturbances are studied. Unlike the classic theory, the sensor signals are transmitted to the estimator or controller over a noisy digital communication link modelled as a stochastic stationary discrete memoryless channel. It is shown that the capability of the noisy channel to ensure almost sure stabilizability/observability of the plant is identical to exactly its capability to transmit information with zero probability of error. Specifically, it is demonstrated that the standard numerical characteristic of the latter capability, i.e., the Shannon zero error capacity of the channel, constitutes the border separating the cases where the plant is and respectively, is not stabilizable/observable with probability 1. },
  Doi                      = {10.1080/002071706000981775},
  Eprint                   = { 
 http://dx.doi.org/10.1080/002071706000981775
 
},
  File                     = {:home/justinpearson/mineng/RelatedWork/002071706000981775.pdf:PDF},
  Url                      = { 
 http://dx.doi.org/10.1080/002071706000981775
 
}
}

@Misc{mcgregorLec17,
  Author                   = {McGregor},

  Review                   = {
This has a proof that

\begin{align}
\frac{2^{n H(r/n)}}{n+1} \le \binom{n}{r} \le 2^{n H(r/n)}
\end{align}

which we can use in the minimum-energy-encoding paper. We use this to bound the log of the binomial coefficients:
 Remarkably, the entropy function bounds
 the binomial coefficients in the following way\draftnote{
 \url{http://people.cs.umass.edu/~mcgregor/711S09/lec17.pdf}}:
 for any $m,n \in \NNInt$ with $0 \le m \le n$, 
 $$
 H\left(\frac{m}{n}\right) - \frac{\log(n+1)}{n} <
 \frac{1}{n} \log \binom{n}{m} <
 H\left(\frac{m}{n}\right).
 $$
 Additionally, if $m \le n/2$, then the sum of the first $m$
 binomial coefficients also lies in this bound:
 \begin{align}\label{entropy_bound}
 H\left(\frac{m}{n}\right) - \frac{\log(n+1)}{n} <
 \frac{1}{n} \log L(n,m) <
 H\left(\frac{m}{n}\right).
 \end{align}
 },
  Url                      = {"\url{http://people.cs.umass.edu/~mcgregor/711S09/lec17.pdf}"}
}

@Misc{cs711,
  Title                    = {Lecture 17 \& 18 – Entropy, Randomness, and Information},

  Author                   = {Andrew McGregor},

  Course                   = {CMPSCI 711: "Really Advanced Algorithms"},
  File                     = {:home/justinpearson/mineng/RelatedWork/lec17.pdf:PDF},
  Retrieved                = {Last Compiled: April 9, 2009},
  Review                   = {I used this in the minenergy paper (Aug 2012) for the entropy bound of
the log sum of binomial coefficients.},
  Url                      = {www.cs.umass.edu/~mcgregor/711S09/lec17.pdf}
}

@Article{minero2009data,
  Title                    = {Data rate theorem for stabilization over time-varying feedback channels},
  Author                   = {Minero, Paolo and Franceschetti, Massimo and Dey, Subhrakanti and Nair, Girish N},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {2009},
  Number                   = {2},
  Pages                    = {243},
  Volume                   = {54},

  File                     = {:home/justinpearson/mineng/RelatedWork/data-rate-thm-TAC.pdf:PDF}
}

@Article{Mitter2001122,
  Title                    = {Control with Limited Information },
  Author                   = {Sanjoy K. Mitter},
  Journal                  = {European Journal of Control },
  Year                     = {2001},
  Number                   = {2–3},
  Pages                    = {122 - 131},
  Volume                   = {7},

  Abstract                 = {"A long-standing open conceptual problem has been the following: How does “information” interact with control of a system, in particular feedback control, and what is the value of “information” in achieving performance objectives for the system through the exercise of control? In answering this question we have to remember that in contrast to a variety of communication settings, the issue of time-delay is of primary importance for control problems, especially control of systems which are unstable. We discuss various issues arising from these fundamental questions. "},
  Doi                      = {http://dx.doi.org/10.3166/ejc.7.122-131},
  File                     = {:home/justinpearson/mineng/RelatedWork/1-s2.0-S0947358001711430-main.pdf:PDF},
  ISSN                     = {0947-3580},
  Keywords                 = {Control with communication},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0947358001711430}
}

@InProceedings{6425874,
  Title                    = {A nonstochastic information theory for feedback},
  Author                   = {Nair, G.N.},
  Booktitle                = {Decision and Control (CDC), 2012 IEEE 51st Annual Conference on},
  Year                     = {2012},
  Month                    = {Dec},
  Pages                    = {1343-1348},

  Abstract                 = {This paper extends a recently proposed theory of nonstochastic maximin information to study feedback systems with erroneous channels. The concepts of conditional and directed maximin information are introduced, without assuming any statistical structure. It is proved that the zero-error feedback capacity of a stationary memoryless channel coincides with the largest rate of directed maximin information across it. This provides a nonstochastic counterpart to recent results in information theory. This characterization is then used to find a tight condition for exponential uniform stabilizability of a linear time-invariant plant over an erroneous channel, consistent with a result of Matveev and Savkin.},
  Doi                      = {10.1109/CDC.2012.6425874},
  File                     = {:home/justinpearson/mineng/RelatedWork/06425874.pdf:PDF},
  ISSN                     = {0743-1546},
  Keywords                 = {asymptotic stability;feedback;information theory;conditional maximin information;directed maximin information;erroneous channels;exponential uniform stabilizability;linear time-invariant plant;nonstochastic information theory;nonstochastic maximin information;stationary memoryless channel;zero-error feedback capacity;Decoding;Joints;Markov processes;Memoryless systems;Uncertainty}
}


@ARTICLE{6415998, 
author={Nair, G.N.}, 
journal={Automatic Control, IEEE Transactions on}, 
title={A Nonstochastic Information Theory for Communication and State Estimation}, 
year={2013}, 
month={June}, 
volume={58}, 
number={6}, 
pages={1497-1510}, 
abstract={In communications, unknown variables are usually modelled as random variables, and concepts such as independence, entropy and information are defined in terms of the underlying probability distributions. In contrast, control theory often treats uncertainties and disturbances as bounded unknowns having no statistical structure. The area of networked control combines both fields, raising the question of whether it is possible to construct meaningful analogues of stochastic concepts such as independence, Markovness, entropy and information without assuming a probability space. This paper introduces a framework for doing so, leading to the construction of a maximin information functional for nonstochastic variables. It is shown that the largest maximin information rate through a memoryless, error-prone channel in this framework coincides with the block-coding zero-error capacity of the channel. Maximin information is then used to derive tight conditions for uniformly estimating the state of a linear time-invariant system over such a channel, paralleling recent results of Matveev and Savkin.}, 
keywords={Channel estimation;Entropy;Indexes;Joints;Stochastic processes;Uncertainty;Erroneous channel;nonprobabilistic information theory;state estimation;zero-error capacity}, 
doi={10.1109/TAC.2013.2241491}, 
ISSN={0018-9286},}



@InProceedings{NairEvans2000,
  Title                    = {Communication-limited stabilization of linear systems},
  Author                   = {Nair, G.N. and Evans, R.J.},
  Booktitle                = {Decision and Control, 2000. Proceedings of the 39th IEEE Conference on},
  Year                     = {2000},
  Pages                    = {1005 -1010},
  Volume                   = {1},

  Abstract                 = {This paper investigates the problem of stabilizing a linear,
discrete-time plant using a digital link with a finite data rate. The
plant model is infinite-dimensional and time-varying, with a
real-valued output which is zero at negative times and distributed
according to a probability density p at time zero. Finite and infinite
horizon costs in terms of the m-th output moment are defined and the
equations of the optimal, finite horizon coder-controller
derived. Asymptotic quantization theory is then used to obtain the
solution as the horizon tends to infinity, without needing to
explicitly solve the finite horizon problem. It is shown that this
limiting coder-controller is optimal with respect to the infinite
horizon cost, provided that p satisfies certain technical
conditions. This immediately leads to a necessary and sufficient
condition for the existence of a coder-controller that takes the m-th
output moment to zero asymptotically with time. If the open-loop plant
is finite-dimensional and time-invariant, this condition simplifies to
an inequality involving the data rate and the open-loop pole with
greatest magnitude. Analogous results automatically hold for the
related problem of state estimation with a finite data rate},
  Annote                   = {"Available at \url{http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=912906}"},
  Doi                      = {10.1109/CDC.2000.912906},
  File                     = {:home/justinpearson/mineng/RelatedWork/00912906.pdf:PDF},
  ISSN                     = {0191-2216},
  Keywords                 = {asymptotic quantization theory;digital link;discrete-time
systems;infinite-dimensional systems;linear systems;probability
density;stabilisation;state estimation;time-varying systems;discrete
time systems;linear systems;multidimensional systems;optimal
control;probability;robust control;state estimation;time-varying
systems;}
}

@Article{nair2011nonstochastic,
  Title                    = {A nonstochastic information theory for communication and state estimation},
  Author                   = {Nair, G.N.},
  Year                     = {2011},

  Abstract                 = {Abstract—In communications, unknown variables are usually
modelled as random variables, and concepts such as indepen-
dence, entropy and information are defined in terms of the
underlying probability distributions. In contrast, control theory
often treats uncertainties and disturbances as bounded unknowns
having no statistical structure. The area of networked control
combines both fields, raising the question of whether it is possible
to construct meaningful analogues of stochastic concepts such
as independence, Markovness, entropy and information without
assuming a probability space. This paper introduces a framework
for doing so, leading to the construction of a maximin information
functional for nonstochastic variables. It is shown that the largest
maximin information rate through a memoryless, error-prone
channel in this framework coincides with the block-coding zero-
error capacity of the channel. Maximin information is then used
to derive tight conditions for uniformly estimating the state of
a linear time-invariant system over such a channel, paralleling
recent results of Matveev and Savkin.},
  File                     = {:home/justinpearson/mineng/RelatedWork/1112.3471.pdf:PDF},
  Publisher                = {IEEE},
  Review                   = {G. N. Nair, “A nonstochastic information theory for communication
and state estimation,” IEEE Trans. Autom. Contr., 2012, provisionally
accepted 29/6/12, preprint available at http://arxiv.org, preliminary
version published in Proc. 9th IEEE Int. Conf. Contr. Automation,
Santiago, Chile, 2011.

Here's my take on this paper. He defines ``uncertain variables'' which are just like RVs but without the pmf, ie, they're a map from an underlying set Omega to some set X of interest. He defines a calculus on these u.v.'s that mirrors standard probability, like independence, conditioning, etc. The idea is that a uv has some range that it maps Omega to, and conditioning on some value of another uv Y, you're just throwing away some the elems of the range. 

An example of this is: consider two uvs X and Y that take values in
scr{X} and sY as you vary omega $\in$ Omega. You could make a matrix A
(initize to 0) with rows for scr{X} and cols for scr{Y} and then pick
an omega to get (X(w),Y(w)) and put a 1 at that element of A. In this
way you'd get a matrix A whose nonzero values tell you where X\&Y
jointly take values. Column j gives you [[ X | j ]] -- it tells you
the subset fo scrX for which X could take values, given that
yY=j. Similar for row i.

Then he talks about partitioning

Then he cooks up a definition of information baesd on how finely you can partition 

Q: Consider the channel with input X in {0,1,2,3,4} and output Y that takes value X or X+1 mod 5 with equal probability. Then


}
}

@Article{NairEvans2003,
  Title                    = {Exponential stabilisability of finite-dimensional linear systems with limited data rates },
  Author                   = {Girish N. Nair and Robin J. Evans},
  Journal                  = {Automatica },
  Year                     = {2003},
  Number                   = {4},
  Pages                    = {585 - 593},
  Volume                   = {39},

  Abstract                 = {A critical notion in the field of communication-limited control is the smallest data rate above which there exists a stabilising coding and control law for a given plant. This quantity measures the lowest rate at which information can circulate in a stable feedback loop and provides a practical guideline for the allocation of communication resources. In this paper, the exponential stabilisability of finite-dimensional LTI plants with limited feedback data rates is investigated. By placing a probability density on the initial state and casting the objective in terms of state moments, the problem is shown to be similar to one in asymptotic quantisation. Quantisation theory is then applied to obtain the infimum stabilising data rate over all causal coding and control laws, under mild requirements on the initial state density.},
  Annote                   = {"Available at \url{http://www.sciencedirect.com/science/article/pii/S0005109802002856}"},
  Doi                      = {http://dx.doi.org/10.1016/S0005-1098(02)00285-6},
  ISSN                     = {0005-1098},
  Keywords                 = {Stabilisability}
}

@Article{nakiboglu2008error,
  Title                    = {Error exponents for variable-length block codes with feedback and cost constraints},
  Author                   = {Nakiboglu, Baris and Gallager, Robert G},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {945--963},
  Volume                   = {54},

  Abstract                 = {Variable-length block-coding schemes are investigated for discrete memoryless channels with ideal feedback under cost constraints. Upper and lower bounds are found for the minimum achievable probability of decoding error Pe,min as a function of constraints R, P, and tau on the transmission rate, average cost, and average block length, respectively. For given R and P, the lower and upper bounds to the exponent -( ln Pe,min )/tau are asymptotically equal as tau rarr infin. The resulting reliability function,limtaurarrinfin(-In Pe,min)/tau as a function of R and V, is concave in the pair (R,P) and generalizes the linear reliability function of Burnashev to include cost constraints. The results are generalized to a class of discrete-time memoryless channels with arbitrary alphabets, including additive Gaussian noise channels with amplitude and power constraints.},
  File                     = {:home/justinpearson/mineng/RelatedWork/0612097.pdf:PDF},
  Publisher                = {IEEE}
}

@Misc{bibfileIntro,
  Author                   = {Justin Pearson},

  Review                   = {
Here is a file for me to write about the papers I've read and what I think about them.
Justin Pearson
May 2012

Review: Some of these may be duplicated from 

\url{https://ccdcsvn.ece.ucsb.edu/svn/ccdc/Papers/bibliography/bibtex_from_joao_webpage.bib}

See various entries in my notes file re: jabref, bibtex, and citations

Note that IEEE Xplorer and Google Books format their bibtex entries
differently. Jason says that one's academic paper should employ
consistent formatting of its


Note: If my paper uses bibliography{this file and
bibtexfromjoaowebpage.bib (joao's bibtex file)}, and there are
duplicate bibtex entries between the two, then we can run into
problems.}
}


@TechReport{PearsonHespanhaLiberzonMay16,
  Title                    = {Control with minimal cost-per-symbol encoding and quasi-optimality of event-based encoders},
  Author                   = {Justin Pearson and Jo{{\~a}}o P. Hespanha and Daniel Liberzon},
  Institution              = {University of California},
  Year                     = {2016},

  Address                  = {Santa Barbara},
  Month                    = {May.},

  Annote                   = {Available at \url{http://www.ece.ucsb.edu/~hespanha/published}},
  Review                   = {A bibtex for our tech report that our journal paper points to.},
  Url                      = {http://www.ece.ucsb.edu/~hespanha/techrep.html}
}



@TechReport{PearsonHespanhaLiberzonMar14,
  Title                    = {Control with Minimum Communication Cost per Symbol},
  Author                   = {Justin Pearson and Jo{{\~a}}o P. Hespanha and Daniel Liberzon},
  Institution              = {University of California},
  Year                     = {2014},

  Address                  = {Santa Barbara},
  Month                    = {Mar.},

  Annote                   = {Available at \url{http://www.ece.ucsb.edu/~hespanha/published}},
  Review                   = {A bibtex for our tech report (not on joao's site yet, but need to get somethign to cite in the conf version of the paper!)},
  Url                      = {http://www.ece.ucsb.edu/~hespanha/techrep.html}
}

@InProceedings{PearsonHespanhaLiberzonDec14,
  author =    {Justin Pearson and Jo{\~a}o Pedro Hespanha and
                  Daniel Liberzon},
  title =    {Control with Minimum Communication Cost per Symbol},
  booktitle =    "Proc. of the 53nd Conf. on Decision and Contr.",
  month =    "Dec.",
  year =    2014,
  Pages                    = {6050--6055},
  annote =       "Available at \url{http://www.ece.ucsb.edu/~hespanha/published}",
}

@InProceedings{PearsonHespanhaLiberzonDec15,
  author =    {Justin Pearson and Jo{\~a}o Pedro Hespanha and
                  Daniel Liberzon},
  title =    {Quasi-optimality of event-based encoders},
  booktitle =    "Proc. of the 54nd Conf. on Decision and Contr.",
  month =    "Dec.",
  year =    2015,
    Pages = {4800--4805},
  annote =       "Available at \url{http://www.ece.ucsb.edu/~hespanha/published}",
abstract={We present an event-triggered controller for stabilizing a continuous-time linear time-invariant system subject to communication constraints. We model the communication constraints as a noiseless finite-capacity communication channel between the process sensors and the controller/actuator. An encoder converts the process state into symbols to send across the channel to the controller/actuator, which converts the symbols into a state estimate to be used in a simple emulation-based state-feedback control law. We derive a sufficient condition for this scheme to stabilize the process. The condition depends on the encoder's average bit-rate, its average consumption of communication resources, and the eigenvalues of the process. The proposed encoding scheme is order-optimal in the sense that its stability condition is within a constant factor of the optimal bound from previous work.}, 
keywords={actuators;continuous time systems;eigenvalues and eigenfunctions;encoding;linear systems;sensors;state estimation;state feedback;telecommunication channels;communication constraints;communication resources;continuous-time linear time-invariant system stabilization;emulation-based state-feedback control law;event-based encoders;event-triggered controller;noiseless finite-capacity communication channel;process sensors;quasioptimality;stability condition;state estimation;Communication channels;Decoding;Eigenvalues and eigenfunctions;Encoding;Process control;Sensors;State estimation}, 
doi={10.1109/CDC.2015.7402968},  
}




@Article{Polyanskiy2010,
  Title                    = {Channel coding rate in the finite blocklength regime},
  Author                   = {Polyanskiy, Yury and Poor, H Vincent and Verd{\'u}, Sergio},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {2010},
  Number                   = {5},
  Pages                    = {2307--2359},
  Volume                   = {56},

  File                     = {PolPooVerMay2010.pdf},
  Publisher                = {IEEE}
}

@Article{polyanskiy2010channel,
  Title                    = {Channel coding rate in the finite blocklength regime},
  Author                   = {Polyanskiy, Yury and Poor, H Vincent and Verd{\'u}, Sergio},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {2010},
  Number                   = {5},
  Pages                    = {2307--2359},
  Volume                   = {56},

  File                     = {polyanskiy2010channel},
  Publisher                = {IEEE}
}

@Book{elvis,
  Title                    = {Turn Me One More Time},
  Author                   = {Elvis Presley},
  Publisher                = {Jail House Books},
  Year                     = {1963},

  Jppkeywords              = {test}
}

@Article{SahaiMitter2006,
  Title                    = {The Necessity and Sufficiency of Anytime Capacity for Stabilization of a Linear System Over a Noisy Communication Link --- Part I: Scalar Systems},
  Author                   = {Sahai, A. and Mitter, S.},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {2006},

  Month                    = {Aug},
  Number                   = {8},
  Pages                    = {3369-3395},
  Volume                   = {52},

  Abstract                 = {In this paper, we review how Shannon's classical notion of capacity is not enough to characterize a noisy communication channel if the channel is intended to be used as part of a feedback loop to stabilize an unstable scalar linear system. While classical capacity is not enough, another sense of capacity (parametrized by reliability) called "anytime capacity" is necessary for the stabilization of an unstable process. The required rate is given by the log of the unstable system gain and the required reliability comes from the sense of stability desired. A consequence of this necessity result is a sequential generalization of the Schalkwijk-Kailath scheme for communication over the additive white Gaussian noise (AWGN) channel with feedback. In cases of sufficiently rich information patterns between the encoder and decoder, adequate anytime capacity is also shown to be sufficient for there to exist a stabilizing controller. These sufficiency results are then generalized to cases with noisy observations, delayed control actions, and without any explicit feedback between the observer and the controller. Both necessary and sufficient conditions are extended to continuous time systems as well. We close with comments discussing a hierarchy of difficulty for communication problems and how these results establish where stabilization problems sit in that hierarchy},
  Doi                      = {10.1109/TIT.2006.878169},
  ISSN                     = {0018-9448},
  Keywords                 = {AWGN channels;channel capacity;channel coding;decoding;linear systems;sequential codes;telecommunication links;telecommunication network reliability;AWGN;Schalkwijk-Kailath scheme;Shannon channel capacity theorem;additive white Gaussian noise;decoder;encoder;feedback loop;linear system;noisy communication link;reliability;scalar system;AWGN;Additive white noise;Communication channels;Communication system control;Decoding;Delay;Feedback loop;Gaussian noise;Linear systems;Stability;Anytime decoding;control over noisy channels;error exponents;feedback;real-time information theory;reliability functions;sequential coding}
}

@Article{schenato2007foundations,
  Title                    = {Foundations of control and estimation over lossy networks},
  Author                   = {Schenato, Luca and Sinopoli, Bruno and Franceschetti, Massimo and Poolla, Kameshwar and Sastry, S Shankar},
  Journal                  = {Proceedings of the IEEE},
  Year                     = {2007},
  Number                   = {1},
  Pages                    = {163--187},
  Volume                   = {95},

  File                     = {:home/justinpearson/mineng/RelatedWork/IEEE_proceedings_2006.pdf:PDF},
  Publisher                = {IEEE}
}

@Misc{shannonZeroError,
  Title                    = {The zero-error capacity of a noisy channel},

  Author                   = {Shannon, C.},

  File                     = {:home/justinpearson/mineng/RelatedWork/01056798.pdf:PDF},
  Review                   = {IRE Trans. Info. Theory, vol. 2, pp. 8–19, 1956.
Shannon, C. ``THE ZERO ERROR CAPACITY OF A NOISY CHANNEL''
Bell Telephone Laboratories,
Murray Hill,
New Jersey
Massachusetts
Institute
of Technology, Cambridge, Mass.}
}

@InBook{shannon1959.pdf,
  Title                    = {Coding Theorems for a Discrete Source With a Fidelity Criterion},
  Author                   = {Shannon, C. and Sloane, N. and Wyner, A. },
  Pages                    = {325- 350},
  Year                     = {1993},

  Booktitle                = {Claude E. Shannon:Collected Papers},
  Doi                      = {Digital Object Identifier: 10.1109/9780470544242.ch21},
  File                     = {:home/justinpearson/mineng/RelatedWork/shannon1959.pdf:PDF}
}

@Book{shannon1993claude,
  Title                    = {Claude Elwood Shannon: collected papers},
  Author                   = {Shannon, C.E. and Sloane, N.J.A. and Wyner, A.D. and IEEE Information Theory Society},
  Publisher                = {IEEE Press},
  Year                     = {1993},

  Chapter                  = {Coding Theorems for a Discrete Source With a Fidelity Criterion. Institute of Radio Engineers, International Convention Record, vol. 7, 1959.},
  File                     = {:home/justinpearson/mineng/RelatedWork/5311476.pdf:PDF},
  ISBN                     = {9780780304345},
  Keywords                 = {Communication, Networking & Broadcasting},
  Lccn                     = {lc92026762},
  Review                   = {
\url{http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5311476&abstractAccess=no&userType=inst}

"there exists a function R(d) (depending on the particular distortion measure and
source) which measures, in a sense, the equivalent rate R of the source (in bits per letter
produced) when d is the allowed distortion level." We know from info theory class that R(d) vs d is decreasing, with R(0) = H(X) I think. So why does it go down? My interpretation: If you're at the receiving end, getting letters from some src-enc-channel-decoder, and you know that the predicted letters from the decoder suffer average distortionn d, then the equivalent \# of bits / symbol you're getting (the information rate) is less, because you're less sure what you're getting. (How is this different from: the noisier the channel, the less information you can get across it per channel use?) 

- what is the set up, here? Is there a noisy channel or just an info src?

"The basic results are roughly that it is impossible to signal at a rate faster than
C / R(d) (source letters per second) over a memoryless channel of capacity C (bits per second)
with a distortion measure less than or equal to d. On the other hand, by sufficiently long block
codes it is possible to approach as closely as desired the rate C / R(d) with distortion level d."

- R(d): bits / output letter
- C: channel signaling rate, bits / sec
- C/R(d): src letters / sec 

Q: sholdn't it be output letters / sec? A: He says that assumes 1 channel use per sec.
Q: Why isn't C in bits / channel use? A: He says that assumes 1 channel use per sec.


Rate distortion: given info src and distortion measure btwn input and output alphabets. The idea is to try to describe input letters with as few bits as possible (Q: How is this different than data compression then?). Then we tx that description (=: codeword) to a rx'r and have it produce an output letter. The distortion between in and out is whawt we suffer. The question is: What's the relationship between ave \# bits we devote per input letter (ie, you'll map n input symbols into $1,...,2^{nR}$) and the exp val of the distortion? R(D). If you devote more than R(D) bits per input letter, then there exists a code that suffers exp val of distortion as close to D as you like.

Similarly, If you insert a channel of capacity C bits / channel-use in your setup, so that you have

|src| ---src-letter--->
 |encoder| ---channel-input-->
 |channel| ---channel-output--->
 |decoder| ---dst-letter-->

Result: A src / dist measure with rate distortion R(D) can be sent over a channel w/ cap C and recovered with dist D iff R(D) < C.

Also: Suppose you want to send $t$ src letters from a src $p(x)$ over a channel w capacity $C$ and the output (which may even be a different alphabet than the src) letters should differ from the src ones by less than $D$ according to distortion measure $d : X \times X' \to \mathbb{R}_{\ge0}$. You need to use the channel at least $t R(D)/C$ times in order to achieve this.

},
  Url                      = {http://ieeexplore.ieee.org/xpl/bkabstractplus.jsp?bkn=5271069}
}

@Article{Shannon:2001:MTC:584091.584093,
  Title                    = {A Mathematical Theory of Communication},
  Author                   = {Shannon, C. E.},
  Journal                  = {SIGMOBILE Mob. Comput. Commun. Rev.},
  Year                     = {2001},

  Month                    = jan,
  Number                   = {1},
  Pages                    = {3--55},
  Volume                   = {5},

  Acmid                    = {584093},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1145/584091.584093},
  File                     = {:home/justinpearson/mineng/RelatedWork/shannon1948.pdf:PDF},
  ISSN                     = {1559-1662},
  Issue_date               = {January 2001},
  Numpages                 = {53},
  Publisher                = {ACM},
  Url                      = {http://doi.acm.org/10.1145/584091.584093}
}

@Article{Shingin20121111,
  Title                    = {Disturbance rejection with information constraints: Performance limitations of a scalar system for bounded and Gaussian disturbances },
  Author                   = {Hidenori Shingin and Yoshito Ohta},
  Journal                  = {Automatica },
  Year                     = {2012},
  Number                   = {6},
  Pages                    = {1111 - 1116},
  Volume                   = {48},

  Abstract                 = {This paper derives performance limitations for disturbance rejection of scalar systems under information c
onstraints subject to either bounded or Gaussian disturbances. Two kinds of disturbance are treated in a unified manner, using appropriate entropies and distortions. It is shown that the achievable performance cannot be improved even if the maximum information constraint is relaxed to an average information constraint. Another observation is that, while the information constraints are weaker than bit-rate or signal-to-noise ratio constraints on the communication channel, the same performance levels are achieved by the best encoder and decoder for disturbance rejection with the information constraints. },
  Doi                      = {http://dx.doi.org/10.1016/j.automatica.2012.02.040},
  File                     = {:home/justinpearson/mineng/RelatedWork/1-s2.0-S000510981200091X-main.pdf:PDF},
  ISSN                     = {0005-1098},
  Keywords                 = {Information constraints},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S000510981200091X}
}

@Article{sinopoli2004kalman,
  Title                    = {Kalman filtering with intermittent observations},
  Author                   = {Sinopoli, Bruno and Schenato, Luca and Franceschetti, Massimo and Poolla, Kameshwar and Jordan, Michael I and Sastry, Shankar S},
  Journal                  = {Automatic Control, IEEE Transactions on},
  Year                     = {2004},
  Number                   = {9},
  Pages                    = {1453--1464},
  Volume                   = {49},

  File                     = {:home/justinpearson/mineng/RelatedWork/tacs04.pdf:PDF},
  Publisher                = {IEEE}
}

@InProceedings{sinopoli2005lqg,
  Title                    = {An LQG optimal linear controller for control systems with packet losses},
  Author                   = {Sinopoli, Bruno and Schenato, Luca and Franceschetti, Massimo and Poolla, Kameshwar and Sastry, Shankar},
  Booktitle                = {Decision and Control, 2005 and 2005 European Control Conference. CDC-ECC'05. 44th IEEE Conference on},
  Year                     = {2005},
  Organization             = {IEEE},
  Pages                    = {458--463},

  File                     = {:home/justinpearson/mineng/RelatedWork/SinopoliLQGOptimal2005.pdf:PDF}
}

@Book{britney,
  Title                    = {Let's Go Oversea To Canada},
  Author                   = {Britney Spears},
  Publisher                = {Blonde, Blondt \& Blondey},
  Year                     = {2007},

  Jppkeywords              = {test}
}

@Article{TabuadaSep2007,
  Title                    = {Event-Triggered Real-Time Scheduling of Stabilizing Control Tasks},
  Author                   = {Tabuada, P.},
  Journal                  = {Automatic Control, IEEE Transactions on},
  Year                     = {2007},

  Month                    = {sept. },
  Number                   = {9},
  Pages                    = {1680 -1685},
  Volume                   = {52},

  Annote                   = {Available at \url{http://www.ee.ucla.edu/~tabuada/Papers/EventTriggered.pdf}},
  Doi                      = {10.1109/TAC.2007.904277},
  File                     = {:home/justinpearson/mineng/RelatedWork/EventTriggered.pdf:PDF},
  ISSN                     = {0018-9286},
  Keywords                 = {asymptotic stability;control unrelated software tasks;embedded processors;event-triggered real-time scheduling;event-triggered scheduler;feedback controller;real-time scheduler;scheduling stabilizing control tasks;asymptotic stability;control engineering computing;embedded systems;feedback;scheduling;task analysis;}
}

@InProceedings{4578659,
  Title                    = {Cooperative control under communication constraints},
  Author                   = {Tatikonda, S.},
  Booktitle                = {Information Theory Workshop, 2008. ITW '08. IEEE},
  Year                     = {2008},
  Month                    = {May},
  Pages                    = {243-246},

  Abstract                 = {Understanding the role of communication in networked control systems is an important and challenging problem. In this paper we determine the communication rates required to achieve a variety of cooperative control objectives. Our results depend heavily on three information theoretic ideas: the directed data processing inequality, Slepian-Wolf coding, and source coding with side-information at the receiver.},
  Doi                      = {10.1109/ITW.2008.4578659},
  File                     = {:home/justinpearson/mineng/RelatedWork/04578659.pdf:PDF},
  Keywords                 = {codes;telecommunication control;Slepian-Wolf coding;communication constraints;cooperative control;directed data processing;networked control systems;source coding;Bandwidth;Communication networks;Communication system control;Control systems;Data processing;Decoding;Equations;Networked control systems;Observability;Source coding}
}

@Article{TatikondaMitter2004,
  Title                    = {Control under communication constraints},
  Author                   = {Tatikonda, S. and Mitter, S.},
  Journal                  = {Automatic Control, IEEE Transactions on},
  Year                     = {2004},

  Month                    = {july},
  Number                   = {7},
  Pages                    = { 1056 - 1068},
  Volume                   = {49},

  Abstract                 = { There is an increasing interest in studying control systems
employing multiple sensors and actuators that are geographically
distributed. Communication is an important component of these
distributed and networked control systems. Hence, there is a need to
understand the interactions between the control components and the
communication components of the distributed system. In this paper, we
formulate a control problem with a communication channel connecting
the sensor to the controller. Our task involves designing the channel
encoder and channel decoder along with the controller to achieve
different control objectives. We provide upper and lower bounds on the
channel rate required to achieve these different control
objectives. In many cases, these bounds are tight. In doing so, we
characterize the "information complexity" of different control
objectives.},
  Annote                   = {Available at \url{http://www.cmi.caltech.edu/events/controlunder_ieee.pdf}},
  Doi                      = {10.1109/TAC.2004.831187},
  File                     = {:home/justinpearson/mineng/RelatedWork/01310461.pdf:PDF},
  Ieeeie                   = {1310461},
  ISSN                     = {0018-9286},
  Keywords                 = { asymptotic observability; asymptotic stabilizability;
communication constraints; discrete time systems; distributed
actuators; distributed control systems; distributed sensors; linear
control; linear systems; multiple sensors; networked control systems;
noiseless digital communication link; actuators; control system
synthesis; discrete time systems; distributed control; distributed
sensors; linear systems; observability; state estimation;
telecommunication channels;},
  Review                   = {\begin{itemize}
 \item ``Information pattern'': what the enc / dec / controller know, and when they know it.
 \item They assume the dec \& controller are separated; they show for enc class one, there's no loss of generality.
 \begin{itemize}
 \item Encoder class 1: 
 \item Encoder class 2:
 \end{itemize}
 \item Linear, disc-time. Enc tx's $R$ bits w/o error per timestep.
 \item Asymptotic observability / stabilizability: W/ normal obsvblty
 in a disc-time sys, after enough time, you can figure out the
 initial state exactly. For this problem setup, at time $t$ you can
 only distinguish btwn $2^tR$ initial states. So we define
 ``asymp. obsvblty''. We say the sys is a.o. if $\exists$ enc/dec
 s.t. $\forall$ controllers, 1. the error $X_t-\hat{X}_t$ can't 
 \item Main result: If an enc/dec/controller enjoys asymptotically observability and stabilizability, then $R > \sum_{\lambda(A)} \max\{0,\log_2 |\lambda(A)| \}$.

 \item Approach: 

 \end{itemize}}
}

@Misc{tatikonda2005,
  Title                    = {The Role of Information Theory in Communication Constrained Control Systems},

  Author                   = {Sekhar C. Tatikonda},

  Date                     = {October 17-18, 2005},
  Event                    = {Workshop on Networked Embedded Sensing and Control},
  File                     = {:home/justinpearson/mineng/RelatedWork/PTalkTatikonda.pdf:PDF},
  Location                 = {Yale University},
  Review                   = {A nice introduction to Tatikonda's work, esp his 2004 paper.}
}

@PhdThesis{48245028,
  Title                    = {Control under communication constraints},
  Author                   = {Sekhar C. Tatikonda},
  Year                     = {2000},

  File                     = {:home/justinpearson/mineng/RelatedWork/48245028.pdf:PDF},
  School                   = {Massachusetts Institute of Technology},
  UrlBooger                      = {http://hdl.handle.net/1721.1/16755}
}

@Article{Teel20131,
  Title                    = {Lyapunov conditions certifying stability and recurrence for a class of stochastic hybrid systems },
  Author                   = {Andrew R. Teel},
  Journal                  = {Annual Reviews in Control },
  Year                     = {2013},
  Number                   = {1},
  Pages                    = {1 - 24},
  Volume                   = {37},

  Doi                      = {http://dx.doi.org/10.1016/j.arcontrol.2013.02.001},
  ISSN                     = {1367-5788},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1367578813000023}
}

@Article{Verdu1990,
  Title                    = {On channel capacity per unit cost},
  Author                   = {Verdu, S.},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {1990},

  Month                    = {sep},
  Number                   = {5},
  Pages                    = {1019 -1030},
  Volume                   = {36},

  Abstract                 = {Memoryless communication channels with arbitrary alphabets where each input symbol is assigned a cost are considered. The maximum number of bits that can be transmitted reliably through the channel per unit cost is studied. It is shown that, if the input alphabet contains a zero-cost symbol, then the capacity per unit cost admits a simple expression as the maximum normalized divergence between two conditional output distributions. The direct part of this coding theorem admits a constructive proof via Stein's lemma on the asymptotic error probability of binary hypothesis tests. Single-user, multiple-access, and interference channels are studied},
  Doi                      = {10.1109/18.57201},
  File                     = {:home/justinpearson/mineng/RelatedWork/00057201.pdf:PDF},
  ISSN                     = {0018-9448},
  Keywords                 = {Stein's lemma;arbitrary alphabets;asymptotic error probability;binary hypothesis tests;channel capacity per unit cost;coding theorem;interference channels;memoryless communication channels;multiple access channels;single user channels;zero-cost symbol;channel capacity;error statistics;information theory;telecommunication channels;},
  Review                   = { Consider a channel with input alphabet $\scr{X}$ and
 output alphabet $\scr{Y}$ and conditional probability distribution
 $p(y|x)$. Definition: An $(n,M)$ \emph{code} is an encoding
 function $f : \{1,\ldots,M\} \to \scr{X}^n$ and a decoder function
 $g : \scr{Y}^n \to \{1,\ldots,M\}$. The idea is that the encoder
 offers $M$ possible messages to send over the channel. Someone
 picks a message $m \in \{1,\ldots,M\}$ to send over the
 channel. The encoder maps $m$ to an $n$-length codeword $f(m)\in
 \scr{X}^n$ and uses the channel $n$ times to send $f(m)$ across
 the channel. This comes out of the channel as $Y \in \scr{Y}^n$, a
 rv. The decoder then guesses that $g(Y) \in \{1,\ldots,M\}$ was
 sent. We're concerned that the reconstruction $g(Y)$ might not
 equal the $m$ that went in, ie, the probability that $g(Y) \ne
 m$. Depending on $p(y|x)$ and the $(f,g)$ code, this might be big
 or small. In other words, given that $m$ went in, what's the
 probability that it is decoded correctly? This probability is conditional on the input message $m$. To get some sort of overall probability of correct decoding, we'd need the chosen
 message $m$ to be a rv. Then we could ask what's the probability
 that the message is decoded correctly. Verdu defines a code's
 \emph{probability of error} to be the average error over all the
 messages.

 The range of $f$ is called the set of \emph{codewords} of the
 code. Since the code takes $n$ channel-uses to transmit one of $M$
 unique symbols, the \emph{rate} of the code if $\frac{\log_2
 M}{n}$ bits per channel-use.

 Shannon showed that every channel has a nonnegative number $C$
 associated with it called its \emph{information channel capacity}
 that has the property that for any number $R$ less than $C$ and
 any $e>0$, there exists a $(n,M)$ code with rate $R$ and
 probability of error $e$.


 Now suppose that transmitting channel input symbol $x \in \scr{X}$
 costs $b(x)$, where $b : \scr{X} \to \NNReal$ maps channel input
 symbols to their transmission costs. Hence an $n$-length codeword
 $x^n \in \scr{X}^n$ costs $\sum_{i=1}^n b(x_i)$.

 The question arises how a limitation

 Definition: An $(n,M,v,e)$ code is a code with $M$ codewords each of length $n$, each of which 


 }
}

@Article{720531,
  Title                    = {Fifty years of Shannon theory},
  Author                   = {Verdú, S.},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {1998},

  Month                    = {Oct},
  Number                   = {6},
  Pages                    = {2057-2078},
  Volume                   = {44},

  Abstract                 = {A brief chronicle is given of the historical development of the central problems in the theory of fundamental limits of data compression and reliable communication},
  Doi                      = {10.1109/18.720531},
  File                     = {:home/justinpearson/mineng/RelatedWork/00720531.pdf:PDF},
  ISSN                     = {0018-9448},
  Keywords                 = {channel capacity;channel coding;data compression;history;information theory;rate distortion theory;reviews;source coding;Shannon theory;channel capacity;channel coding;data compression;fundamental limits;history;overview;rate distortion theory;reliable communication;source coding;Bandwidth;Channel capacity;Data compression;Frequency modulation;Information theory;Phase change materials;Pulse modulation;Reliability theory;Telegraphy;Vocoders}
}

@Article{verdu1994general,
  Title                    = {A general formula for channel capacity},
  Author                   = {Verdu, Sergio and Han, Te},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {1994},
  Number                   = {4},
  Pages                    = {1147--1157},
  Volume                   = {40},

  Abstract                 = {A formula for the capacity of arbitrary single-user channels without feedback (not necessarily information stable, stationary, etc.) is proved. Capacity is shown to equal the supremum, over all input processes, of the input-output inf-information rate defined as the liminf in probability of the normalized information density. The key to this result is a new converse approach based on a simple new lower bound on the error probability of m-ary hypothesis tests among equiprobable hypotheses. A necessary and sufficient condition for the validity of the strong converse is given, as well as general expressions for ε-capacity},
  File                     = {:home/justinpearson/mineng/RelatedWork/00335960.pdf:PDF},
  Publisher                = {IEEE}
}

@InProceedings{verhaegh2013extension,
  Title                    = {Extension and evaluation of model-based periodic event-triggered control},
  Author                   = {Verhaegh, JLC and Gommans, TMP and Heemels, WPMH},
  Booktitle                = {Control Conference (ECC), 2013 European},
  Year                     = {2013},
  Organization             = {IEEE},
  Pages                    = {1138--1144},

  Abstract                 = {Abstract— Periodic event-triggered control (PETC) is a con-
trol strategy that combines ideas from conventional periodic
sampled-data control and event-triggered control. By commu-
nicating periodically sampled sensor and controller data only
when needed to guarantee stability and performance properties,
PETC is capable of reducing the number of transmissions
significantly, while still retaining a satisfactory closed-loop
behavior. In this paper, we provide an extension of an existing
model-based PETC strategy for linear systems by including an
(approximate) disturbance model. This extension can further
enhance communication savings in the presence of disturbances.
In addition, we evaluate the extended model-based PETC strat-
egy by comparing this strategy to the standard model-based
PETC and to a model-based periodic time-triggered control
(PTTC) strategy. In this PTTC strategy, data is transmitted at
fixed sampling times. For the evaluation, we present techniques
for stability and 2 -gain performance analysis for both the
PETC strategy and the PTTC strategy. Finally, the advantage
of the (extended) PETC strategy over the PTTC strategy will
be demonstrated by providing numerical examples.
},
  File                     = {:home/justinpearson/mineng/RelatedWork/VerGom_ECC_13.pdf:PDF}
}

@Misc{kostina2013channels2,
  Title                    = {Channels with cost constraints: strong converse and dispersion},

  Author                   = {Victoria Kostina, Sergio Verdu},

  Abstract                 = {Abstract—This paper shows the strong converse and the disper-
sion of memoryless channels with cost constraints. The analysis
is based on a new non-asymptotic converse bound expressed in
terms of the distribution of a random variable termed the b-tilted
information density, which plays a role similar to that of the
information density in channel coding without cost constraints.
We also analyze the fundamental limits of lossy joint-source-
channel coding over channels with cost constraints.},
  File                     = {:home/justinpearson/mineng/RelatedWork/channelswithcost.pdf:PDF}
}

@Book{wang2008networked,
  Title                    = {Networked Control Systems: Theory and Applications},
  Author                   = {Wang, F.Y. and Liu, D.},
  Publisher                = {Springer},
  Year                     = {2008},

  Abstract                 = { Networked control systems (NCS) consist of sensors, actuators and controllers the operations of which may be distributed over geographically disparate locations and co-ordinated by the exchange of information passed over a communication network. The communication network may be physically wired or not. The widespread applications of the Internet have been a major driving force for research and development of NCS. NCS have advantages in terms of cost reduction, system diagnosis and flexibility, minimizing wiring and making the addition and replacement of individual elements relatively simple; efficient data sharing makes taking globally intelligent control decisions easier with an NCS.},
  Annote                   = {"Available at \url{http://books.google.com/books?id=WqZulJqBdFMC}"},
  File                     = {:home/justinpearson/mineng/RelatedWork/978-1-84800-215-9_3.pdf:PDF},
  ISBN                     = {9781848002159},
  Lccn                     = {2008927633}
}

@Misc{wiki:resetattack,
  Title                    = {TCP reset attack --- Wikipedia{,} The Free Encyclopedia},

  Author                   = {Wikipedia},
  Note                     = {[Online; accessed 18-March-2014]},
  Year                     = {2014},

  Url                      = {http://en.wikipedia.org/w/index.php?title=TCP_reset_attack&oldid=590714059}
}

@Misc{wiki:tcp,
  Title                    = {Transmission Control Protocol --- Wikipedia{,} The Free Encyclopedia},

  Author                   = {Wikipedia},
  Note                     = {[Online; accessed 18-March-2014]},
  Year                     = {2014},

  Url                      = {http://en.wikipedia.org/w/index.php?title=Transmission_Control_Protocol&oldid=598618059}
}

@Misc{wiki:weibull,
  Title                    = {Weibull distribution --- Wikipedia{,} The Free Encyclopedia},

  Author                   = {Wikipedia},
  Note                     = {[Online; accessed 20-March-2014]},
  Year                     = {2014},

  Url                      = {http://en.wikipedia.org/w/index.php?title=Weibull_distribution&oldid=599820613}
}

@Misc{wiki:tcpslowstart,
  Title                    = {Slow-start --- Wikipedia{,} The Free Encyclopedia},

  Author                   = {Wikipedia},
  Note                     = {[Online; accessed 20-March-2014]},
  Year                     = {2013},

  Url                      = {http://en.wikipedia.org/w/index.php?title=Slow-start&oldid=578870936}
}

@Misc{wiki:blah,
  Title                    = {Plagiarism --- {W}ikipedia{,} The Free Encyclopedia},

  Author                   = {Wikipedia},
  Note                     = {[Online; accessed 22-July-2004]},
  Year                     = {2004},

  Url                      = {http://en.wikipedia.org/w/index.php?title=Plagiarism&oldid=5139350}
}

@InProceedings{wolf2004zero,
  Title                    = {Zero-error information and applications in cryptography},
  Author                   = {Wolf, Stefan and Wultschleger, J},
  Booktitle                = {Information Theory Workshop, 2004. IEEE},
  Year                     = {2004},
  Organization             = {IEEE},
  Pages                    = {1--6},

  File                     = {:home/justinpearson/mineng/RelatedWork/WolWul04.pdf:PDF}
}

@Article{763226,
  Title                    = {Systems with finite communication bandwidth constraints. II. Stabilization with limited information feedback},
  Author                   = {Wing Shing Wong and Brockett, R.W.},
  Journal                  = {Automatic Control, IEEE Transactions on},
  Year                     = {1999},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {1049-1053},
  Volume                   = {44},

  Abstract                 = {For part I, see ibid., vol.42, p.1294-8, 1997. In this paper a new class of feedback control problems is introduced. Unlike classical models, the systems considered here have communication channel constraints. As a result, the issue of coding and communication protocol becomes an integral part of the analysis. Since these systems cannot be asymptotically stabilized if the underlying dynamics are unstable, a weaker stability concept called containability is introduced. A key result connects containability with an inequality equation involving the communication data rate and the rate of change of the state},
  Doi                      = {10.1109/9.763226},
  File                     = {:home/justinpearson/mineng/RelatedWork/00763226.pdf:PDF},
  ISSN                     = {0018-9286},
  Keywords                 = {feedback;information theory;memoryless systems;stability;coding;communication data rate;communication protocol;containability;feedback control problems;finite communication bandwidth constraints;limited information feedback;Adaptive control;Asymptotic stability;Bandwidth;Channel capacity;Communication channels;Communication system control;Control systems;Delay;Feedback control;Protocols}
}

@Article{623096,
  Title                    = {Systems with finite communication bandwidth constraints. I. State estimation problems},
  Author                   = {Wing Shing Wong and Brockett, R.W.},
  Journal                  = {Automatic Control, IEEE Transactions on},
  Year                     = {1997},

  Month                    = {Sep},
  Number                   = {9},
  Pages                    = {1294-1299},
  Volume                   = {42},

  Abstract                 = {In this paper, we investigate a state estimation problem involving finite communication capacity constraints. Unlike classical estimation problems where the observation is a continuous process corrupted by additive noises, there is a constraint that the observations must be coded and transmitted over a digital communication channel with finite capacity. This problem is formulated mathematically, and some convergence properties are defined. Moreover, the concept of a finitely recursive coder-estimator sequence is introduced. A new upper bound for the average estimation error is derived for a large class of random variables. Convergence properties of some coder-estimator algorithms are analyzed. Various conditions connecting the communication data rate with the rate of change of the underlying dynamics are established for the existence of stable and asymptotically convergent coder-estimator schemes},
  Doi                      = {10.1109/9.623096},
  File                     = {:home/justinpearson/mineng/RelatedWork/00623096.pdf:PDF},
  ISSN                     = {0018-9286},
  Keywords                 = {convergence;data communication;probability;recursive estimation;state estimation;stochastic processes;telecommunication channels;communication data rate;convergence;digital communication channel;finite communication bandwidth constraints;hybrid systems;observations;prefix code;random variables;recursive coder-estimator;state estimation;upper bound;Additive noise;Algorithm design and analysis;Bandwidth;Channel capacity;Convergence;Digital communication;Estimation error;Random variables;State estimation;Upper bound}
}

@Article{1055508,
  Title                    = {The rate-distortion function for source coding with side information at the decoder},
  Author                   = {Wyner, A.D. and Ziv, J.},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {1976},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {1-10},
  Volume                   = {22},

  Doi                      = {10.1109/TIT.1976.1055508},
  File                     = {:home/justinpearson/mineng/RelatedWork/wynerziv.pdf:PDF},
  ISSN                     = {0018-9448},
  Keywords                 = {Rate-distortion theory;Binary sequences;Decoding;Distortion measurement;Encoding;Jacobian matrices;Random variables;Rate-distortion;Source coding;Switches}
}

@Article{2600,
  Title                    = {On runlength codes},
  Author                   = {Zehavi, E. and Wolf, J.K.},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {1988},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {45-54},
  Volume                   = {34},

  Abstract                 = {Several results on binary (d, k) codes are given. First, a novel derivation for the capacity of these codes based on information-theoretic principles is given. Based on this result the spectrum of a (d, k) code is computed. Finally, the problem of computing the capacity of the binary symmetric channel under the condition that the input sequences satisfy the (d, k ) constraint is considered. Lower bounds on the capacity of such a channel are derived},
  Doi                      = {10.1109/18.2600},
  File                     = {:home/justinpearson/mineng/RelatedWork/00002600.pdf:PDF},
  ISSN                     = {0018-9448},
  Keywords                 = {binary sequences;channel capacity;codes;(d, k) code;binary codes;binary sequence;binary symmetric channel;channel capacity;information-theoretic principles;runlength codes;Binary sequences;Capacity planning;Digital recording;Information rates;Information theory;Interference constraints;Intersymbol interference;Magnetic recording;Postal services;Random variables}
}


@article{nair2007feedback,
  title={Feedback control under data rate constraints: An overview},
  author={Nair, Girish N and Fagnani, Fabio and Zampieri, Sandro and Evans, Robin J},
  journal={Proceedings of the IEEE},
  volume={95},
  number={1},
  pages={108--137},
  year={2007},
  publisher={IEEE},
  File                     = {:home/justinpearson/mineng/RelatedWork/nairPIEEE07.pdf:PDF},
}

@INPROCEEDINGS{4177795, 
author={Kofman, E. and Braslavsky, J.H.}, 
booktitle={Decision and Control, 2006 45th IEEE Conference on}, 
title={Level Crossing Sampling in Feedback Stabilization under Data-Rate Constraints}, 
year={2006}, 
month={Dec}, 
pages={4423-4428}, 
abstract={This paper introduces a novel event-driven sampled-data feedback scheme where the plant output samples are triggered by the crossings - with hysteresis - of the signal through its quantization levels. The plant and controller communicate over binary channels that operate asynchronously and are assumed to be error and delay-free. The paper proposes two systematic output feedback control design strategies. The first strategy consists in the digital emulation of a previously designed analog controller. The second strategy is a simple direct design that drives the plant state to the origin in finite time after a total transmission of 2n + 2 bits, where n is the order of the plant}, 
keywords={control system synthesis;feedback;hysteresis;sampled data systems;analog controller;data-rate constraints;event-driven sampled-data feedback;feedback stabilization;level crossing sampling;quantization level;systematic output feedback control design;Communication system control;Control design;Control systems;Delay effects;Emulation;Feedback communications;Hysteresis;Open loop systems;Quantization;Sampling methods}, 
doi={10.1109/CDC.2006.377483},
Review = {
  \begin{itemize}
  \item analog plant: SISO CT finite-dim LTI sys, x not measured directly, x0 unknown, assumes no disturbance or noise
  \item Comm: noiseless delay-free digital channel btwn sensor
    measuring y and the digital controller. We send 1/0 over it
    aperiodically. Also there's a noiseless dig ch btwn dig controller
    and plant.
  \item Actuator can only produce inputs $\{-pU,\ldots,-U,0,U,\ldots,pU\}$.
  \item Q: Need to assume ctrlblty / obsrvblty?
  \item Assumes that the tx times are detected exactly (bc assumed no disturbance or noise) and tx'd w/ inf precision with no delays.
  \item Idea: Send nothing most of the time. Run the scalar output y thru a quantizer. When $y-y_s=h$, send a 1-bit. When $y-y_s=-h$, send a 0-bit.
  \item Scheme that compares output to quantized output is called``Level-crossing sampling'' (LCS)
  \item Result: describes a ctrl scheme that drives plant state to origin after txing $2n+2$ bits ($n$ is dim of sys).
  \item Result seems like it encodes the state info in the tx times.
  \item Not a great paper.
  \end{itemize}
  }

}

@article{Lunze2010211,
title = "A state-feedback approach to event-based control ",
journal = "Automatica ",
volume = "46",
number = "1",
pages = "211 - 215",
year = "2010",
note = "",
issn = "0005-1098",
doi = "http://dx.doi.org/10.1016/j.automatica.2009.10.035",
urlbooger = "http://www.sciencedirect.com/science/article/pii/S0005109809004968",
author = "Jan Lunze and Daniel Lehmann",
keywords = "Event-based control",
keywords = "State-feedback control",
keywords = "Performance",
keywords = "Networked control system ",
abstract = "This paper proposes a new method for event-based state-feedback control in which a control input generator mimics a continuous feedback between two consecutive event times. The performance of the event-based control system is evaluated by comparing this loop with the continuous state-feedback loop. An upper bound of the difference between both loops is derived, which shows that the approximation of the continuous state-feedback loop by the event-based control loop can be made arbitrarily tight by appropriately choosing the threshold parameter of the event generator. ",
File = {:home/justinpearson/mineng/RelatedWork/1-s2.0-S0005109809004968-main.pdf:PDF},
Review = {
Availble at "http://www.sciencedirect.com/science/article/pii/S0005109809004968"

  \begin{itemize}
  \item Plant: Finite-dim LTI {\bf stable} sys with full-state output and bounded unknown disturbance.
  \item Assumes you've found a good state-feedback $K$ that rejects
    disturbances, etc. But you won't be running the system in
    state-feedback mode (ctsly sending the state). Instead, an
    ``event-generator'' monitors the state and only sends the state
    once in a while.
  \item ``Event-generator'': reads the state, internally runs a
    closed-loop model with \emph{estimated} disturbance (estimated
    based on how the true state differs from the internal model) (the
    estimate is constant most of the time, only updated during tx's)
    . When the true state differs more than $\overline{e}$ (you pick
    this number) from the internal model's state (at time $t_k$ say),
    the event-gen sends the inf-precision true state $x(t_k)$ to the
    ``control input generator''.
  \item ``Control input generator'': Runs its own internal model and
    picks actuation signal $u(t)$ to be just state feedback
    $-Kx_\text{internal}(t)$. When it rx's a true state, it resets its model's state.
  \item Result 1: The mag of the difference btwn (1) the state traj with
    this event-based setup and (2) the state traj you'd enjoy if you
    were doing traditional state-feedback is bounded by
    \begin{align*}
      \overline{e} \int_0^\infty \| e^{(A -BK) \tau} B K \| d\tau
    \end{align*}
  \item Result 2: Assume the disturbance is never farther than
    $d_{\max}$ from its estimated value (not sure how we ensure
    this). A lower bound on the time between 2 tx's is $T$ satisfying
    \begin{align*}
      \int_0^T \| e^{A \tau} E\| d \tau = \overline{e}/d_{\max}.
    \end{align*}
  \item Big idea: Suppose you've got a stable plant w/ disturbance and you've chosend a tate feedback gain $K$ that results in a acceptable performance. Here is an event-based scheme that achieves trajectories as close to the state-fdbk one as you like (Q: for all ICs?)
  \item {\bf Shortcoming:} Inf-precision comm channel. 
  \end{itemize}
  }
}


@inproceedings{lehmann2010event,
  title={Event-based control using quantized state information},
  author={Lehmann, Daniel and Lunze, Jan},
  booktitle =    "Proc. of the 2nd IFAC Workshop on Distributed Estimation and Control in Networked Systems (NecSys'10)",
  year =         2010,
  month =        "Sep.",
  pages={1--6},
File = {:home/justinpearson/mineng/RelatedWork/0003.pdf:PDF},
  Review = {
    \begin{itemize}
    \item Very similar setup to prev one (2010 Automatica: "A state-feedback approach to event-based control'')
    \item LTI sys w/ disturbances, full-state observed
    \item Setup: event-monitor runs an internal sim of the sys and
      tx's something when the diff btwn true state and model gets too
      big. What it tx's is: it puts a box around the enc/dec's sim of
      the state. The actual state will be on the boundary of this
      box. It chops up the box into pieces (a grid) and tx's the index
      of the piece where the true state lies. (It doesn't devote any
      indices to the inner boxes bc the true state will never lie in
      an inner box.) The dec uses that index and subtracts the center
      of that box from its internal model's state. The controller uses
      state feedback of the sim'd state.
    \item Btw, the number of indices is $l^n-(l-2)^n$ so the required
      num of bits is the $\log_2$ of that. But how freq might we need
      to send an index? See below.
    \item Results:
      Like 2010 Automatica, the error btwn the state traj under this scheme and the state traj w/ cts full-state feedback is bdd by the prev eqn.
    \item Minimum time btwn successive tx's: $T$ satisfying (here, $l$ is the number of pieces that you chop each dimension into):
      \begin{align*}
        \begin{cases}
          \| e^{A T} \|_\infty = l & \text{no disturbances} \\
          \int_0^T \|e^{A t}E\|_\infty dt = \frac{\overline{e}}{d_{\max}} \left( 1-\frac{\max_t \|e^{At}\|_\infty}{l} \right) & \text{with disturbances}
        \end{cases}.
      \end{align*}
    \item Shortcomings: Doesn't do much with the bit-rate of the channel. Doesn't say, eg, if $R>blah$, then this scheme will ultimately bound the system.
    \item Could compare this one to our min-energy one.
    \end{itemize}
  }
}

@INPROCEEDINGS{6315501, 
author={Tallapragada, P. and Chopra, N.}, 
booktitle={American Control Conference (ACC), 2012}, 
title={On Co-design of event trigger and quantizer for emulation based control}, 
year={2012}, 
month={June}, 
pages={3772-3777}, 
abstract={In this paper the inter-dependence of quantization and event-triggered control is investigated. We motivate the idea of co-designing the event-trigger and the quantizer for emulation based discrete-event control, and then propose a methodology for designing emulation based discrete-event controllers for asymptotic stabilization of general nonlinear systems. The proposed algorithm results in an easily implementable finite density logarithmic quantizer and a simple event-trigger. The resulting emulation based discrete-event controller semi-globally asymptotically stabilizes the origin of the system with a specified arbitrary compact region of attraction. The quantizer is designed to be endowed with hysteresis so as to avoid chattering of the controller. The proposed design is illustrated with a two-dimensional nonlinear system.}, 
keywords={asymptotic stability;control nonlinearities;control system synthesis;discrete event systems;multidimensional systems;nonlinear control systems;controller chattering avoidance;emulation based discrete-event controller design;event trigger-quantizer codesign;event-triggered control;finite density logarithmic quantizer;general nonlinear systems;hysteresis;quantization interdependence;semiglobally asymptotic stabilization;two-dimensional nonlinear system;Control systems;Emulation;Erbium;Hysteresis;Lyapunov methods;Nonlinear systems;Quantization}, 
doi={10.1109/ACC.2012.6315501}, 
ISSN={0743-1619},
File = {:home/justinpearson/mineng/RelatedWork/2012ACC_Codesign_event_trig_quantizer.pdf:PDF},
Review = {
  \begin{itemize}
  \item Uses Andy's hybrid framework.
  \item Works for nonlinear systems.
   \item He expresses the closed loop event triggered quantized system as a hybrid system. Jumps correspond to ``An event'' in the traditional event-triggered control sense. The problem comes down to figuring out how many levels the quantizer should have and what the flow and jump sets should be. Those are related to the event-triggering condition.
  \item Does not explicitly find min time btwen jumps (Q: could be research paper topic?)
  \item Non-constructive: there exists a constant $\tau_d>0$ such that
    for all solutions starting in $R \backslash A$ the jumps are
    separated by at least an amount of time $\tau_d$.
  \item Idea: On one hand, event-triggered control usually assumes inf-precision quantizer (ie, you send the whole real-valued thing). OTOH, a quantizer may have arb. complex quantization regions. Therefore we should design them together.
  \end{itemize}

  }
}

@inproceedings{li2012stabilizing,
  title={Stabilizing bit-rates in quantized event triggered control systems},
  author={Li, Lichun and Wang, Xiaofeng and Lemmon, Michael},
  booktitle={Proceedings of the 15th ACM international conference on Hybrid Systems: Computation and Control},
  pages={245--254},
  year={2012},
  organization={ACM},
File = {:home/justinpearson/mineng/RelatedWork/hscc028-liPS.pdf:PDF},
abstract={Event triggered systems are feedback systems that sample the
   state when the novelty in that state exceeds a
   threshold. Prior work has demonstrated that
   event-triggered feedback may have inter-sampling
   intervals that are, on average, greater than the
   sampling periods found in comparably performing
   periodic sampled data systems. This fact has been
   used to justify the claim that event-triggered
   systems are more efficient in their use of
   communication or computational resources than
   periodic sampled data systems. If, however, one
   accounts for quantization effects and maximum
   acceptable delays, then it is quite possible that
   the actual bit-rates generated by event triggered
   systems may be greater than that of periodically
   triggered systems. This paper examines the bit-rates
   required to asymptotically stabilize nonlinear
   event triggered systems. An increasing upper bound
   on the stabilizing bit-rate with respect to the norm
   of the state is derived. This increasing upper bound
   on the stabilizing bit-rate reveals the efficient
   attentiveness property of event triggered systems,
   i.e. the farther the state is away from the origin,
   the higher the stabilizing bit-rate will
   be. Moreover, this paper presents the conditions
   under which the stabilizing bit-rates asymptotically
   go to 0.},
Review = {
  \begin{itemize}
  \item ``An accurate measure of channel usage is the bit-rate as
    defined by hte number of bits per sampled state divided by the
    acceptable delaye in message delivery.'' {\bf ????} Would need to see some examples?
  \item Super confusing. Theorem 5.11 points to Thm 5.7, which points
    to Thm 4.8 and Eqns (30), (34), and (41), and Thm 4.8 assumes
    (16), (20), and (21) hold. UGH.
  \item Main idea: Nonlinear plant. State read by event-detector. ED samples state and sends to quantizer, which sends some \# of bits across an error-free channel that delays it by some positive time that may vary but not go over the next sampled time. 
  \item Result: ``Stabilizing bit-rate'' $:=$ bit-rate sufficient to guarantee the asymp stability of the system. (Something like the \# of bits sent by the quantizer divided by the delay suffered by that txion.) They find conditions for which an upper bound on it exists and find more conditions under which it actually goes to 0 as the state goes to 0. So, the farther the state is away from the origin, the higher bit-rate is needed to stabilize the event triggered system.
  \item ``Stabilizing bit-rate is the bit-rate which is sufficient to guarantee the asymptotic stability of the system. We first show, in subsection 5.1, that under some conditions, the stabilizing bit-rate is always bounded from above by a continuous increasing function with respect to (w.r.t.) the norm of the state. Then, in subsection 5.2, it is found that under the same conditions, the stabilizing bit-rate asymptotically converges to a finite number as the state approaches 0. In some cases, the stabilizing bit-rate goes to 0 as state x approaches 0. These results indicate that under some conditions, the event triggered system is efficient attentive, i.e. the stabilizing bit-rate monotonically decreases as the system converges to its equilibrium point.''
  \end{itemize}
}
}


@ARTICLE{2014arXiv1405.6196T,
   author = {{Tallapragada}, P. and {Cortes}, J.},
    title = {Event-Triggered Stabilization of Linear Systems Under Bounded Bit Rates},
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1405.6196},
 keywords = {Computer Science - Systems and Control, Mathematics - Optimization and Control},
     year = 2014,
    month = may,
   adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1405.6196T},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
abstract = {This paper addresses the problem of exponential practical stabilization of linear time-invariant systems with disturbances using event-triggered control and bounded communication bit rate. We consider both the case of instantaneous communication with finite precision data at each transmission and the case of non-instantaneous communication with bounded communication rate. Given a prescribed rate of convergence, the proposed event-triggered control implementations opportunistically determine the transmission instants and the finite precision data to be transmitted on each transmission. We show that our design exponentially practically stabilizes the origin while guaranteeing a uniform positive lower bound on the inter-transmission and inter-reception times, ensuring that the number of bits transmitted on each transmission is upper bounded uniformly in time, and allowing for the possibility of transmitting fewer bits at any given time if more bits than prescribed were transmitted earlier. We also characterize the necessary and sufficient average data rate for exponential practical stabilization. Several simulations illustrate the results.},
Review = {
  \begin{itemize}
  \item I met Pavan at ITA 2014. After my talk he asked for my slides, which I emailed him.
  \item Plant: LTI sys w/ bounded disturbance (w/ known bound), full state observable.
  \item Sensor chooses tx times (ahead of time?) and tx's some number of bits that may vary btwn tx's.
  \item Comm line may introduce a delay whose size may vary from tx to tx.
  \item Dynamic quantization
  \item Enc \& dec both know the rx times 
  \item Control objective: Keep some Lyapunov function $V(x(t))$ below an exponentially-decaying (but possibly offset above 0) function.
  \item Bit-rate def'n: asymptotic: $\lim_{t \to \infty} \frac{\text{\# bits tx'd in time interval $[t_0,t]$}}{t-t_0}$
  \item Result: design of an event-triggered enc/dec that decides tx times and \# bits to tx each time. Given a desired convergence rate, the strategy confines the plant to a compact set, guarantees a uniform pos lower bnd on inter-tx times and ensures that \# bits tx'd each time is unifly upper bdd.
  \end{itemize}
}
}

@InProceedings{HespanhaLiberzonMorseDec00,
  author =       {Jo{\~a}o Pedro Hespanha and Daniel Liberzon and
                  A.~Stephen Morse},
  title =        {Bounds on the Number of Switchings with
                  Scale-Independent Hysteresis: Applications to
                  Supervisory Control},
  booktitle =    "Proc. of the 39th Conf. on Decision and Contr.",
  pages =        {3622-3627},
  year =         2000,
  volume =       4,
  month =        "Dec.",
  annote =       "Available at \url{http://www.ece.ucsb.edu/~hespanha/published}",
File = {:home/justinpearson/mineng/RelatedWork/tr-hy-bound.ps:PDF},
}



@incollection{lemmon2010event,
  title={Event-triggered feedback in control, estimation, and optimization},
  author={Lemmon, Michael},
  booktitle={Networked Control Systems},
  pages={293--358},
  year={2010},
  publisher={Springer},
url = {http://www3.nd.edu/~lemmon/publications/2010/event-trigger-siena-final.pdf},
File = {:home/justinpearson/mineng/RelatedWork/event-trigger-siena-final.pdf:PDF},
}


@article{nesic2004input,
  title={Input-output stability properties of networked control systems},
  author={Nesic, Dragan and Teel, Andrew R},
  journal={Automatic Control, IEEE Transactions on},
  volume={49},
  number={10},
  pages={1650--1667},
  year={2004},
  publisher={IEEE},
  File = {:home/justinpearson/mineng/RelatedWork/lp-ncs-nesic-teel.pdf:PDF},

}

@InCollection{CogillLallHespanhaMar10,
  author =       {Randy Cogill and Sanjay Lall and Jo{\~a}o Pedro Hespanha},
  title =        {A Constant Factor Approximation Algorithm for Event-Based
                  Sampling},
  booktitle =    {Perspectives in Mathematical System Theory, Control, and
                  Signal Processing},
  pages =        {51--60},
  publisher =    {Springer-Verlag},
  year =         2010,
  editor =       {Jan C. Willems and Shinji Hara and Yoshito Ohta and Hisaya
                  Fujioka},
  number =       398,
  series =       {Lecture Notes in Control and Information Sciences},
  chapter =      {A Constant Factor Approximation Algorithm for Event-Based
                  Sampling},
  address =      {Berlin},
  month =        "Mar.",
  annote =       "Available at \url{http://www.ece.ucsb.edu/~hespanha/published}",
  File = {/Users/justin/PhD/CCDC/Papers/2012-minimum-energy-encoding/RelatedWork/2007ACC_1443_FI.pdf}
}



@INPROCEEDINGS{1582293, 
author={Imer, O.C. and Basar, T.}, 
booktitle={Decision and Control, 2005 and 2005 European Control Conference. CDC-ECC '05. 44th IEEE Conference on}, 
title={Optimal Estimation with Limited Measurements}, 
year={2005}, 
month={Dec}, 
pages={1029-1034}, 
abstract={We consider a sequential estimation problem with two decision makers, or agents, who work as members of a team. One of the agents sits at an observation post, and makes sequential observations about the state of an underlying stochastic process for a fixed period of time. The observer agent upon observing the process makes a decision as to whether to disclose some information about the process to the other agent who acts as an estimator. The estimator agent sequentially estimates the state of the process. The agents have the common objective of minimizing a performance criterion with the constraint that the observer agent may only act a limited number of times.}, 
keywords={Decoding;Distortion measurement;Estimation error;Length measurement;Monitoring;Observers;Recursive estimation;State estimation;Stochastic processes;Wireless sensor networks}, 
doi={10.1109/CDC.2005.1582293},
File = {01582293.pdf}
}



@inproceedings{rinaldi2016synchronizing,
  title={Synchronizing low-cost probes for IEC61850 transfer time estimation},
  author={Rinaldi, Stefano and Ferrari, Paolo and Loda, Matteo},
  booktitle={Precision Clock Synchronization for Measurement, Control, and Communication (ISPCS), 2016 IEEE International Symposium on},
  pages={1--6},
  year={2016},
  organization={IEEE},
  review = {https://www.dropbox.com/s/ty4vr2ibuwtlls6/P1.pdf?dl=0

IEC 61850 - some network protocol over ethernet

- IEC 61850 is a communication standard for electrical substation automation systems.
    - https://en.wikipedia.org/wiki/IEC_61850

- using BB PRU smart-grid IEEE 1588 grid.
- BB ran linux & xenomai (RT framework for linux) simultaneously (??) for precision timestamping.
- PTP daemon on each BB
- GPIO reads 1PPS signal, caught/timestamped by Xenomai & relayed to Linux.

- Xenomai is a hack layer that hijacks the linux scheduler. Better to let Linux run as normal & use the built-in PRU for real-time stuff -- out of the box, no extra installation.
},
  file = {/Users/justin/Projects/Roseline/ReadingGroup/2016-09-14_Roseline-campus-udpates/Synchronizing Low-Cost Probes for IEC61850 Transfer Time Estimation P1.pdf}
}



@inproceedings{netland2013software,
  title={Software Module Real-Time Target: Improving Development of Embedded Control System by Including Simulink Generated Code into Existing Code},
  author={Netland, {\O}yvind and Skavhaug, Amund},
  booktitle={2013 39th Euromicro Conference on Software Engineering and Advanced Applications},
  pages={232--235},
  year={2013},
  organization={IEEE},
  review = {
- http://www.itk.ntnu.no/smrt/index.php

- main idea: Matlab's Simulink Coder tool generates embedded code. However, additional code is necessary to interface it with your specifici hardware. It is hard to add this custom code to the code that was generated by SImulink Coder. The authors present Software Module Real-Time target (SMRT), which is:

MathWorks Simulink is used for modeling and simulation of dynamic mathematical models. A plugin, Simulink Coder, can generate C code based on Simulink models. Software Module Real-Time Target (SMRT) is a method that creates a shared library from the code generated by Simulink. This library can be used by other software projects, and there is defined a simple mechanism for communication between this project and the SMRT library. The SMRT concept has been implemented for Xenomai Linux on a Beaglebone development board. The Beaglebone is a suitable board for many embedded applications, since it is small, inexpensive and have good I/O capabilities.

  },
  file = {06619516.pdf},
}



@article{bes2015create,
  title={How to create a very-low-cost, very-low-power, credit-card-sized and real-time-ready datalogger},
  author={B{\`e}s de Berc, Maxime and Grunberg, Marc and Engels, Fabien},
  journal={Advances in Geosciences},
  volume={40},
  pages={37--41},
  year={2015},
  publisher={Copernicus GmbH},
  review = {
- use a bbb's ADC for seismic data monitoring
- needed 1kHz sampling of adcs -- used PRU 
  },
  file = {adgeo-40-37-2015.pdf}
}

@inproceedings{mcpherson2015environment,
  title={An environment for submillisecond-latency audio and sensor processing on BeagleBone Black},
  author={McPherson, Andrew and Zappi, Victor},
  booktitle={Audio Engineering Society Convention 138},
  year={2015},
  organization={Audio Engineering Society},
  file={mcpherson_aes2015.pdf},
  notes = {

- they made BeagleRT
    - made a cape too
- runs on Xenomai 
    - xenomai runs above linux kernel task scheduler

- Running audio at higher priority than the Linux kernel means that kernel hardware drivers cannot be used. *ugh*
- real-time audio effects of musical instruments

- Example of beaglert in use:
    - https://www.youtube.com/watch?v=O7Z7T7aUdFE


  }
}

@book{molloy2014exploring,
  title={Exploring BeagleBone: Tools and Techniques for Building with Embedded Linux},
  author={Molloy, Derek},
  year={2014},
  publisher={John Wiley \& Sons}
}